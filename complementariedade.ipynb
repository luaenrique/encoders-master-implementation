{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Carrega logits e labels de um arquivo .npz\"\"\"\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        logits = data['logits']\n",
    "        labels = data['labels']\n",
    "        return logits, labels\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def logits_to_predictions(logits):\n",
    "    \"\"\"Converte logits em predi√ß√µes\"\"\"\n",
    "    return np.argmax(logits, axis=1)\n",
    "\n",
    "def load_dataset(base_path, dataset_name):\n",
    "    \"\"\"Carrega test set para um dataset\"\"\"\n",
    "\n",
    "    patterns = {\n",
    "        'BERT': f\"bert-base-uncased_{dataset_name}_test.npz\",\n",
    "        'ELECTRA': f\"electra-base-discriminator_{dataset_name}_test.npz\",\n",
    "        'RoBERTa': f\"logits_roberta-base_{dataset_name}_test.npz\"\n",
    "    }\n",
    "\n",
    "    folders = {\n",
    "        'BERT': 'logits_google-bert',\n",
    "        'ELECTRA': 'logits_electra',\n",
    "        'RoBERTa': 'logits_roberta'\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüîç Carregando {dataset_name.upper()}...\")\n",
    "\n",
    "    all_predictions = {}\n",
    "    labels = None\n",
    "\n",
    "    for model_name, filename in patterns.items():\n",
    "        folder = folders[model_name]\n",
    "        file_path = os.path.join(base_path, folder, filename)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            logits, lbls = load_data(file_path)\n",
    "            if logits is not None:\n",
    "                all_predictions[model_name] = logits_to_predictions(logits)\n",
    "                if labels is None:\n",
    "                    labels = lbls\n",
    "                print(f\"‚úÖ {model_name}: {len(logits)} amostras\")\n",
    "        else:\n",
    "            print(f\"‚ùå {model_name}: arquivo n√£o encontrado\")\n",
    "\n",
    "    return all_predictions, labels\n",
    "\n",
    "def create_agreement_matrix(pred1, pred2, labels, n_classes):\n",
    "    \"\"\"\n",
    "    Cria matriz de concord√¢ncia entre dois modelos\n",
    "\n",
    "    Matriz 2x2:\n",
    "    - [0,0]: Ambos errados\n",
    "    - [0,1]: Modelo 1 errado, Modelo 2 correto\n",
    "    - [1,0]: Modelo 1 correto, Modelo 2 errado\n",
    "    - [1,1]: Ambos corretos\n",
    "    \"\"\"\n",
    "\n",
    "    correct1 = (pred1 == labels).astype(int)\n",
    "    correct2 = (pred2 == labels).astype(int)\n",
    "\n",
    "    agreement_matrix = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        agreement_matrix[correct1[i], correct2[i]] += 1\n",
    "\n",
    "    return agreement_matrix\n",
    "\n",
    "def create_detailed_agreement_matrix(pred1, pred2, n_classes):\n",
    "    \"\"\"\n",
    "    Cria matriz de concord√¢ncia detalhada (classe por classe)\n",
    "    Mostra quantas vezes cada par de predi√ß√µes ocorre\n",
    "    \"\"\"\n",
    "\n",
    "    agreement_matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "\n",
    "    for i in range(len(pred1)):\n",
    "        agreement_matrix[pred1[i], pred2[i]] += 1\n",
    "\n",
    "    return agreement_matrix\n",
    "\n",
    "\n",
    "def analyze_dataset_2(predictions, labels, dataset_name):\n",
    "    \"\"\"Analisa Kappa, Matriz de Confus√£o e Concord√¢ncia\"\"\"\n",
    "\n",
    "    if len(predictions) != 3 or labels is None:\n",
    "        print(f\"‚ùå Dados incompletos para {dataset_name}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"AN√ÅLISE: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    models = ['BERT', 'ELECTRA', 'RoBERTa']\n",
    "    n_classes = len(np.unique(labels))\n",
    "    class_names = [f'C{i}' for i in range(n_classes)]\n",
    "\n",
    "    # 1. Accuracy individual\n",
    "    print(\"ACCURACY INDIVIDUAL:\")\n",
    "    for model in models:\n",
    "        acc = accuracy_score(labels, predictions[model])\n",
    "        print(f\"  {model:8}: {acc:.4f}\")\n",
    "\n",
    "    # 2. Kappa de Cohen\n",
    "    print(f\"\\nKAPPA DE COHEN:\")\n",
    "    pairs = [('BERT', 'ELECTRA'), ('BERT', 'RoBERTa'), ('ELECTRA', 'RoBERTa')]\n",
    "\n",
    "    for m1, m2 in pairs:\n",
    "        kappa = cohen_kappa_score(predictions[m1], predictions[m2])\n",
    "        print(f\"  {m1} vs {m2:8}: {kappa:.4f}\")\n",
    "\n",
    "    # 3. Matrizes de Confus√£o (original)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig.suptitle(f'Confusion Matrices - {dataset_name.upper()}', fontsize=14)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        cm = confusion_matrix(labels, predictions[model])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   ax=axes[i])\n",
    "        axes[i].set_title(model)\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('True label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. NOVA: Matrizes de Concord√¢ncia (Correto/Incorreto)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig.suptitle(f'Agreement Matrices (Correct/Incorrect) - {dataset_name.upper()}', fontsize=14)\n",
    "\n",
    "    agreement_labels = ['Incorrect', 'Correct']\n",
    "\n",
    "    for i, (m1, m2) in enumerate(pairs):\n",
    "        agreement_matrix = create_agreement_matrix(\n",
    "            predictions[m1], predictions[m2], labels, n_classes\n",
    "        )\n",
    "\n",
    "        # Calcular percentuais\n",
    "        percentages = agreement_matrix / agreement_matrix.sum() * 100\n",
    "\n",
    "        # Criar anota√ß√µes com count e percentual\n",
    "        annot_text = np.empty_like(agreement_matrix, dtype=object)\n",
    "        for row in range(2):\n",
    "            for col in range(2):\n",
    "                annot_text[row, col] = f'{agreement_matrix[row, col]}\\n({percentages[row, col]:.1f}%)'\n",
    "\n",
    "        sns.heatmap(agreement_matrix, annot=annot_text, fmt='', cmap='RdYlGn',\n",
    "                   xticklabels=[f'{m2}\\n{label}' for label in agreement_labels],\n",
    "                   yticklabels=[f'{m1}\\n{label}' for label in agreement_labels],\n",
    "                   ax=axes[i])\n",
    "        axes[i].set_title(f'{m1} vs {m2}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 5. NOVA: Matrizes de Concord√¢ncia Detalhada (Classe por Classe)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig.suptitle(f'Detailed Agreement Matrices (Class-by-Class) - {dataset_name.upper()}', fontsize=14)\n",
    "\n",
    "    for i, (m1, m2) in enumerate(pairs):\n",
    "        detailed_matrix = create_detailed_agreement_matrix(\n",
    "            predictions[m1], predictions[m2], n_classes\n",
    "        )\n",
    "\n",
    "        sns.heatmap(detailed_matrix, annot=True, fmt='d', cmap='YlOrRd',\n",
    "                   xticklabels=[f'{m2}\\n{name}' for name in class_names],\n",
    "                   yticklabels=[f'{m1}\\n{name}' for name in class_names],\n",
    "                   ax=axes[i])\n",
    "        axes[i].set_title(f'{m1} vs {m2}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 6. NOVA: Estat√≠sticas de Concord√¢ncia\n",
    "    print(f\"\\nESTAT√çSTICAS DE CONCORD√ÇNCIA:\")\n",
    "    for m1, m2 in pairs:\n",
    "        agreement_matrix = create_agreement_matrix(\n",
    "            predictions[m1], predictions[m2], labels, n_classes\n",
    "        )\n",
    "\n",
    "        total = agreement_matrix.sum()\n",
    "        both_correct = agreement_matrix[1, 1]\n",
    "        both_wrong = agreement_matrix[0, 0]\n",
    "        total_agreement = both_correct + both_wrong\n",
    "\n",
    "        print(f\"\\n  {m1} vs {m2}:\")\n",
    "        print(f\"    Ambos corretos:   {both_correct:4d} ({both_correct/total*100:.1f}%)\")\n",
    "        print(f\"    Ambos errados:    {both_wrong:4d} ({both_wrong/total*100:.1f}%)\")\n",
    "        print(f\"    Concord√¢ncia total: {total_agreement:4d} ({total_agreement/total*100:.1f}%)\")\n",
    "        print(f\"    Discord√¢ncia:     {total-total_agreement:4d} ({(total-total_agreement)/total*100:.1f}%)\")\n",
    "\n",
    "def analyze_dataset(predictions, labels, dataset_name):\n",
    "    \"\"\"Analisa Kappa e Matriz de Confus√£o\"\"\"\n",
    "\n",
    "    if len(predictions) != 3 or labels is None:\n",
    "        print(f\"‚ùå Dados incompletos para {dataset_name}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"AN√ÅLISE: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    models = ['BERT', 'ELECTRA', 'RoBERTa']\n",
    "\n",
    "    # 1. Accuracy individual\n",
    "    print(\"ACCURACY INDIVIDUAL:\")\n",
    "    for model in models:\n",
    "        acc = accuracy_score(labels, predictions[model])\n",
    "        print(f\"  {model:8}: {acc:.4f}\")\n",
    "\n",
    "    # 2. Kappa de Cohen\n",
    "    print(f\"\\nKAPPA DE COHEN:\")\n",
    "    pairs = [('BERT', 'ELECTRA'), ('BERT', 'RoBERTa'), ('ELECTRA', 'RoBERTa')]\n",
    "\n",
    "    for m1, m2 in pairs:\n",
    "        kappa = cohen_kappa_score(predictions[m1], predictions[m2])\n",
    "        print(f\"  {m1} vs {m2:8}: {kappa:.4f}\")\n",
    "\n",
    "    # 3. Matrizes de Confus√£o\n",
    "    if dataset_name in ['emotion', 'amazonpolarity']:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        fig.suptitle(f'Confusion Matrixes - {dataset_name.upper()}', fontsize=14)\n",
    "\n",
    "        n_classes = len(np.unique(labels))\n",
    "        class_names = [f'C{i}' for i in range(n_classes)]\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            cm = confusion_matrix(labels, predictions[model])\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names,\n",
    "                    ax=axes[i])\n",
    "            axes[i].set_title(model)\n",
    "            axes[i].set_xlabel('Predicted')\n",
    "            axes[i].set_ylabel('True label')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # AJUSTE O CAMINHO AQUI\n",
    "    base_path = \"./\"\n",
    "\n",
    "    datasets = ['amazonpolarity', 'banking77', 'huffpost', 'emotion', 'clincoos']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        try:\n",
    "            predictions, labels = load_dataset(base_path, dataset)\n",
    "            if predictions and labels is not None:\n",
    "                analyze_dataset(predictions, labels, dataset)\n",
    "                analyze_dataset_2(predictions, labels, dataset)\n",
    "            else:\n",
    "                print(f\"‚ùå Falhou ao carregar {dataset}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro em {dataset}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ An√°lise conclu√≠da!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
