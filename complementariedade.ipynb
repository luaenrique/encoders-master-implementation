{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Carrega logits e labels de um arquivo .npz\"\"\"\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        logits = data['logits']\n",
    "        labels = data['labels']\n",
    "        return logits, labels\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def logits_to_predictions(logits):\n",
    "    \"\"\"Converte logits em predi√ß√µes\"\"\"\n",
    "    return np.argmax(logits, axis=1)\n",
    "\n",
    "def load_dataset(base_path, dataset_name):\n",
    "    \"\"\"Carrega test set para um dataset\"\"\"\n",
    "\n",
    "    patterns = {\n",
    "        'BERT': f\"bert-base-uncased_{dataset_name}_test.npz\",\n",
    "        'ELECTRA': f\"electra-base-discriminator_{dataset_name}_test.npz\",\n",
    "        'RoBERTa': f\"logits_roberta-base_{dataset_name}_test.npz\"\n",
    "    }\n",
    "\n",
    "    folders = {\n",
    "        'BERT': 'logits_google-bert',\n",
    "        'ELECTRA': 'logits_electra',\n",
    "        'RoBERTa': 'logits_roberta'\n",
    "    }\n",
    "\n",
    "    print(f\"\\nüîç Carregando {dataset_name.upper()}...\")\n",
    "\n",
    "    all_predictions = {}\n",
    "    labels = None\n",
    "\n",
    "    for model_name, filename in patterns.items():\n",
    "        folder = folders[model_name]\n",
    "        file_path = os.path.join(base_path, folder, filename)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            logits, lbls = load_data(file_path)\n",
    "            if logits is not None:\n",
    "                all_predictions[model_name] = logits_to_predictions(logits)\n",
    "                if labels is None:\n",
    "                    labels = lbls\n",
    "                print(f\"‚úÖ {model_name}: {len(logits)} amostras\")\n",
    "        else:\n",
    "            print(f\"‚ùå {model_name}: arquivo n√£o encontrado\")\n",
    "\n",
    "    return all_predictions, labels\n",
    "\n",
    "def analyze_dataset(predictions, labels, dataset_name):\n",
    "    \"\"\"Analisa Kappa e Matriz de Confus√£o\"\"\"\n",
    "\n",
    "    if len(predictions) != 3 or labels is None:\n",
    "        print(f\"‚ùå Dados incompletos para {dataset_name}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"AN√ÅLISE: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    models = ['BERT', 'ELECTRA', 'RoBERTa']\n",
    "\n",
    "    # 1. Accuracy individual\n",
    "    print(\"ACCURACY INDIVIDUAL:\")\n",
    "    for model in models:\n",
    "        acc = accuracy_score(labels, predictions[model])\n",
    "        print(f\"  {model:8}: {acc:.4f}\")\n",
    "\n",
    "    # 2. Kappa de Cohen\n",
    "    print(f\"\\nKAPPA DE COHEN:\")\n",
    "    pairs = [('BERT', 'ELECTRA'), ('BERT', 'RoBERTa'), ('ELECTRA', 'RoBERTa')]\n",
    "\n",
    "    for m1, m2 in pairs:\n",
    "        kappa = cohen_kappa_score(predictions[m1], predictions[m2])\n",
    "        print(f\"  {m1} vs {m2:8}: {kappa:.4f}\")\n",
    "\n",
    "    # 3. Matrizes de Confus√£o\n",
    "    if dataset_name in ['emotion', 'amazonpolarity']:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        fig.suptitle(f'Confusion Matrixes - {dataset_name.upper()}', fontsize=14)\n",
    "\n",
    "        n_classes = len(np.unique(labels))\n",
    "        class_names = [f'C{i}' for i in range(n_classes)]\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            cm = confusion_matrix(labels, predictions[model])\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, yticklabels=class_names,\n",
    "                    ax=axes[i])\n",
    "            axes[i].set_title(model)\n",
    "            axes[i].set_xlabel('Predicted')\n",
    "            axes[i].set_ylabel('True label')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    # AJUSTE O CAMINHO AQUI\n",
    "    base_path = \"./\"\n",
    "\n",
    "    datasets = ['amazonpolarity', 'banking77', 'huffpost', 'emotion', 'clincoos']\n",
    "\n",
    "    for dataset in datasets:\n",
    "        try:\n",
    "            predictions, labels = load_dataset(base_path, dataset)\n",
    "            if predictions and labels is not None:\n",
    "                analyze_dataset(predictions, labels, dataset)\n",
    "            else:\n",
    "                print(f\"‚ùå Falhou ao carregar {dataset}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro em {dataset}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ An√°lise conclu√≠da!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
