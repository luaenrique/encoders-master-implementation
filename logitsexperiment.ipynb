{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26971b63-4690-48dc-84a7-b271ed32cc76",
   "metadata": {},
   "source": [
    "Logits Experiment (Lua Zangrande)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573fb5b-d192-46c1-8151-327e32735533",
   "metadata": {},
   "outputs": [],
   "source": [
    "Starting by defining a global seed to allow it to be repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb788cd-ec73-4fcd-bfa4-6787baef237b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4666c6f2-ccf2-4635-820f-debc64b69c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# NÃO setar nenhuma seed\n",
    "# Ou, se já tiver setado, redefinir com valores aleatórios\n",
    "torch.manual_seed(torch.seed())  # gera uma seed aleatória nova\n",
    "np.random.seed(None)              # None faz o NumPy escolher seed aleatória\n",
    "random.seed(None)                 # None faz o random escolher seed aleatória\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(torch.seed())  # nova seed aleatória para GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ed8a021-7943-4799-855e-712380988cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2421771601.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mBefore anything, we have to define our model, we chose a simple MLP because it should be enough to process logits/embeddings\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Before anything, we have to define our model, we chose a simple MLP because it should be enough to process logits/embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c39c97f-f46e-4998-a4e1-76d94df7b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def create_model(input_dim, hidden_dim1, dropout, num_classes=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, hidden_dim1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(hidden_dim1, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, num_classes)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "247a077c-4c5b-4b60-9b2e-7c4cf0f5f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def trainNNEmb(\n",
    "    bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings,\n",
    "    bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings,\n",
    "    trainLabels, testLabels,\n",
    "    num_classes,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "    # Concatena os logits das três redes\n",
    "    concatenated_logits = np.concatenate(\n",
    "        [bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings], axis=1\n",
    "    )\n",
    "    concatenated_test_logits = np.concatenate(\n",
    "        [bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings], axis=1\n",
    "    )\n",
    "\n",
    "    train_labels = np.array(trainLabels)\n",
    "    test_labels = np.array(testLabels)\n",
    "\n",
    "    # Split treino/val a partir do conjunto de treino\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        concatenated_logits,\n",
    "        train_labels,\n",
    "        test_size=val_size,\n",
    "        stratify=train_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cria DataLoaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(concatenated_test_logits, dtype=torch.float32), torch.tensor(test_labels, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    param_grid = {\n",
    "        'lr': [1e-3, 5e-4],\n",
    "        'hidden_dim1': [64, 128],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for params in combinations:\n",
    "        print(f\"Testando: {params}\")\n",
    "        model = create_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim1=params['hidden_dim1'],\n",
    "            dropout=params['dropout'],\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Treina por 5 epochs\n",
    "        for epoch in range(5):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Avaliação no conjunto de validação\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    print(\"Melhores parâmetros:\", best_params)\n",
    "    print(\"Menor loss na validação:\", best_loss)\n",
    "\n",
    "    # Avaliação final no conjunto de teste\n",
    "    best_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = best_model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    print(f\"AccuracyNN: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "240b1214-3e58-4e6b-802d-501d3b3c8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainNNEmbPatienceStack(\n",
    "    bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings,\n",
    "    bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings,\n",
    "    trainLabels, testLabels,\n",
    "    num_classes,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    max_epochs=20,\n",
    "    patience=3,  # número de epochs sem melhora antes de parar\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "    # Concatena embeddings/logits\n",
    "    X_train_full = np.stack([bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings], axis=1)\n",
    "    X_test = np.stack([bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings], axis=1)\n",
    "    y_train_full = np.array(trainLabels)\n",
    "    y_test = np.array(testLabels)\n",
    "\n",
    "    # Split treino/val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=val_size, stratify=y_train_full, random_state=42\n",
    "    )\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Grid de hiperparâmetros\n",
    "    param_grid = {\n",
    "        'lr': [1e-3, 5e-4],\n",
    "        'hidden_dim1': [64, 128],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    best_loss_overall = float('inf')\n",
    "    best_params_overall = None\n",
    "    best_model_overall = None\n",
    "\n",
    "    for params in combinations:\n",
    "        print(f\"\\nTestando parâmetros: {params}\")\n",
    "        model = create_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim1=params['hidden_dim1'],\n",
    "            dropout=params['dropout'],\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            # Treino\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # Validação\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item() * X_batch.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss={epoch_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                best_model_state = model.state_dict()\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping na epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        # Recupera melhor versão do modelo\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "        # Atualiza melhor modelo do grid\n",
    "        if best_val_loss < best_loss_overall:\n",
    "            best_loss_overall = best_val_loss\n",
    "            best_params_overall = params\n",
    "            best_model_overall = model\n",
    "\n",
    "    print(\"\\nMelhores parâmetros encontrados:\", best_params_overall)\n",
    "    print(\"Menor loss na validação:\", best_loss_overall)\n",
    "\n",
    "    # Avaliação final no teste\n",
    "    best_model_overall.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = best_model_overall(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    print(f\"Accuracy no conjunto de teste: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "238d16ad-724e-4bed-b207-a1daf67999c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def trainNNEmbPatience(\n",
    "    bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings,\n",
    "    bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings,\n",
    "    trainLabels, testLabels,\n",
    "    num_classes,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    max_epochs=20,\n",
    "    patience=3,  # número de epochs sem melhora antes de parar\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "    # Concatena embeddings/logits\n",
    "    X_train_full = np.concatenate([bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings], axis=1)\n",
    "    X_test = np.concatenate([bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings], axis=1)\n",
    "    y_train_full = np.array(trainLabels)\n",
    "    y_test = np.array(testLabels)\n",
    "\n",
    "    # Split treino/val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=val_size, stratify=y_train_full, random_state=42\n",
    "    )\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Grid de hiperparâmetros\n",
    "    param_grid = {\n",
    "        'lr': [1e-3, 5e-4],\n",
    "        'hidden_dim1': [64, 128],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    best_loss_overall = float('inf')\n",
    "    best_params_overall = None\n",
    "    best_model_overall = None\n",
    "\n",
    "    for params in combinations:\n",
    "        print(f\"\\nTestando parâmetros: {params}\")\n",
    "        model = create_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim1=params['hidden_dim1'],\n",
    "            dropout=params['dropout'],\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = None\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            # Treino\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            # Validação\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in val_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item() * X_batch.size(0)\n",
    "            val_loss /= len(val_loader.dataset)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss={epoch_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                epochs_no_improve = 0\n",
    "                best_model_state = model.state_dict()\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping na epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "        # Recupera melhor versão do modelo\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "        # Atualiza melhor modelo do grid\n",
    "        if best_val_loss < best_loss_overall:\n",
    "            best_loss_overall = best_val_loss\n",
    "            best_params_overall = params\n",
    "            best_model_overall = model\n",
    "\n",
    "    print(\"\\nMelhores parâmetros encontrados:\", best_params_overall)\n",
    "    print(\"Menor loss na validação:\", best_loss_overall)\n",
    "\n",
    "    # Avaliação final no teste\n",
    "    best_model_overall.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = best_model_overall(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    print(f\"Accuracy no conjunto de teste: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d35ed48-c640-4546-841e-21a3fe66e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def trainNNEmb_random(\n",
    "    bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings,\n",
    "    bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings,\n",
    "    trainLabels, testLabels,\n",
    "    num_classes,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    n_trials=20,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "    # Concatena embeddings ou logits\n",
    "    concatenated_train = np.concatenate([bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings], axis=1)\n",
    "    concatenated_test = np.concatenate([bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings], axis=1)\n",
    "\n",
    "    train_labels = np.array(trainLabels)\n",
    "    test_labels = np.array(testLabels)\n",
    "\n",
    "    # Split treino/val\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        concatenated_train, train_labels, test_size=val_size, stratify=train_labels, random_state=42\n",
    "    )\n",
    "\n",
    "    # DataLoaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(concatenated_test, dtype=torch.float32), torch.tensor(test_labels, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    # Espaços contínuos para random search\n",
    "    lr_range = (1e-4, 5e-3)\n",
    "    hidden_range = (32, 256)\n",
    "    dropout_range = (0.2, 0.5)\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        # Amostra aleatoriamente os hiperparâmetros\n",
    "        lr = 10**np.random.uniform(np.log10(lr_range[0]), np.log10(lr_range[1]))\n",
    "        hidden_dim1 = random.randint(hidden_range[0], hidden_range[1])\n",
    "        dropout = np.random.uniform(dropout_range[0], dropout_range[1])\n",
    "\n",
    "        print(f\"Trial {trial+1}/{n_trials} - lr: {lr:.5f}, hidden_dim1: {hidden_dim1}, dropout: {dropout:.2f}\")\n",
    "\n",
    "        model = create_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim1=hidden_dim1,\n",
    "            dropout=dropout,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Treino por 5 epochs (pode ajustar)\n",
    "        for epoch in range(5):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            print(f\"  Epoch {epoch+1} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Validação\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_params = {'lr': lr, 'hidden_dim1': hidden_dim1, 'dropout': dropout}\n",
    "            best_model = model\n",
    "\n",
    "    print(\"Melhores parâmetros encontrados:\", best_params)\n",
    "    print(\"Menor loss na validação:\", best_loss)\n",
    "\n",
    "    # Teste final\n",
    "    best_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = best_model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    print(f\"Accuracy final: {correct / total:.4f}\")\n",
    "\n",
    "    return best_model, best_params, best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d78429-eed2-4ab7-81d4-56c71e21e257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8cb178c2-8bd5-4f61-9db1-620b6ecaddd2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "514b7e38-0b69-41a9-866a-6d15d43cecf9",
   "metadata": {},
   "source": [
    "IMDB + Logits test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b55716dd-f04a-49af-9a0c-cd37d3559bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logits', 'labels']\n",
      "(16000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "bert_logits_file = np.load('logits_google-bert/bert-base-uncased_emotion_train_bert-base-uncased.npz')\n",
    "roberta_logits_file = np.load('logits_roberta-base_emotion_train_roberta-base.npz')\n",
    "electra_logits_file = np.load('logits_google/electra-base-discriminator_emotion_train_electra-base-discriminator.npz')\n",
    "\n",
    "\n",
    "bert_logits_test_file = np.load('logits_google-bert/bert-base-uncased_emotion_test_bert-base-uncased.npz')\n",
    "roberta_logits_test_file = np.load('logits_roberta-base_emotion_test_roberta-base.npz')\n",
    "electra_logits_test_file = np.load('logits_google/electra-base-discriminator_emotion_test_electra-base-discriminator.npz')\n",
    "\n",
    "print(electra_logits_file.files)  # Ex: ['bert_logits', 'roberta_logits', 'electra_logits']\n",
    "\n",
    "# Acessa um array específico\n",
    "bert_logits = bert_logits_file['logits']\n",
    "\n",
    "print(bert_logits.shape)  # Verifica dimensão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3fee2337-5d04-4006-9b3c-35063b3bb61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import itertools\n",
    "\n",
    "def trainNNEmbf1(\n",
    "    bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings,\n",
    "    bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings,\n",
    "    trainLabels, testLabels,\n",
    "    num_classes,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "):\n",
    "    # Concatena os logits das três redes\n",
    "    concatenated_logits = np.concatenate(\n",
    "        [bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings], axis=1\n",
    "    )\n",
    "    concatenated_test_logits = np.concatenate(\n",
    "        [bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings], axis=1\n",
    "    )\n",
    "\n",
    "    train_labels = np.array(trainLabels)\n",
    "    test_labels = np.array(testLabels)\n",
    "\n",
    "    # Split treino/val a partir do conjunto de treino\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        concatenated_logits,\n",
    "        train_labels,\n",
    "        test_size=val_size,\n",
    "        stratify=train_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Cria DataLoaders\n",
    "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "    test_dataset = TensorDataset(torch.tensor(concatenated_test_logits, dtype=torch.float32), torch.tensor(test_labels, dtype=torch.long))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    param_grid = {\n",
    "        'lr': [1e-3, 5e-4],\n",
    "        'hidden_dim1': [64, 128],\n",
    "        'dropout': [0.3, 0.5]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for params in combinations:\n",
    "        print(f\"Testando: {params}\")\n",
    "        model = create_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_dim1=params['hidden_dim1'],\n",
    "            dropout=params['dropout'],\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Treina por 5 epochs\n",
    "        for epoch in range(5):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * X_batch.size(0)\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            print(f\"Epoch {epoch+1} - Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Avaliação no conjunto de validação\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item() * X_batch.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    print(\"Melhores parâmetros:\", best_params)\n",
    "    print(\"Menor loss na validação:\", best_loss)\n",
    "\n",
    "    # Avaliação final no conjunto de teste com F1-score\n",
    "    best_model.eval()\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = best_model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_true_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Calcula accuracy\n",
    "    accuracy = sum(p == t for p, t in zip(all_predictions, all_true_labels)) / len(all_predictions)\n",
    "\n",
    "    # Calcula F1-score\n",
    "    f1_weighted = f1_score(all_true_labels, all_predictions, average='weighted')\n",
    "    f1_macro = f1_score(all_true_labels, all_predictions, average='macro')\n",
    "    f1_micro = f1_score(all_true_labels, all_predictions, average='micro')\n",
    "\n",
    "    print(f\"AccuracyNN: {accuracy:.4f}\")\n",
    "    print(f\"F1-score (weighted): {f1_weighted:.4f}\")\n",
    "    print(f\"F1-score (macro): {f1_macro:.4f}\")\n",
    "    print(f\"F1-score (micro): {f1_micro:.4f}\")\n",
    "\n",
    "    # Para um relatório completo\n",
    "    print(\"\\nRelatório de classificação:\")\n",
    "    print(classification_report(all_true_labels, all_predictions))\n",
    "    \n",
    "    return best_model, best_params, accuracy, f1_weighted, f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d823c5e1-b882-4d9d-a199-bee3666092cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f149ee4-1876-4380-b696-f754b8ed4b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.1726\n",
      "Epoch 2 - Loss: 0.0528\n",
      "Epoch 3 - Loss: 0.0441\n",
      "Epoch 4 - Loss: 0.0434\n",
      "Epoch 5 - Loss: 0.0428\n",
      "Val Loss: 0.0443\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.2053\n",
      "Epoch 2 - Loss: 0.0592\n",
      "Epoch 3 - Loss: 0.0507\n",
      "Epoch 4 - Loss: 0.0500\n",
      "Epoch 5 - Loss: 0.0465\n",
      "Val Loss: 0.0428\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.1248\n",
      "Epoch 2 - Loss: 0.0458\n",
      "Epoch 3 - Loss: 0.0448\n",
      "Epoch 4 - Loss: 0.0418\n",
      "Epoch 5 - Loss: 0.0421\n",
      "Val Loss: 0.0420\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.1269\n",
      "Epoch 2 - Loss: 0.0485\n",
      "Epoch 3 - Loss: 0.0479\n",
      "Epoch 4 - Loss: 0.0422\n",
      "Epoch 5 - Loss: 0.0432\n",
      "Val Loss: 0.0396\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.2313\n",
      "Epoch 2 - Loss: 0.0509\n",
      "Epoch 3 - Loss: 0.0464\n",
      "Epoch 4 - Loss: 0.0448\n",
      "Epoch 5 - Loss: 0.0415\n",
      "Val Loss: 0.0395\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.3156\n",
      "Epoch 2 - Loss: 0.0673\n",
      "Epoch 3 - Loss: 0.0576\n",
      "Epoch 4 - Loss: 0.0527\n",
      "Epoch 5 - Loss: 0.0521\n",
      "Val Loss: 0.0411\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.1839\n",
      "Epoch 2 - Loss: 0.0467\n",
      "Epoch 3 - Loss: 0.0439\n",
      "Epoch 4 - Loss: 0.0403\n",
      "Epoch 5 - Loss: 0.0407\n",
      "Val Loss: 0.0394\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.2212\n",
      "Epoch 2 - Loss: 0.0515\n",
      "Epoch 3 - Loss: 0.0479\n",
      "Epoch 4 - Loss: 0.0441\n",
      "Epoch 5 - Loss: 0.0420\n",
      "Val Loss: 0.0420\n",
      "Melhores parâmetros: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Menor loss na validação: 0.03939528465809417\n",
      "AccuracyNN: 0.9290\n",
      "F1-score (weighted): 0.9285\n",
      "F1-score (macro): 0.8800\n",
      "F1-score (micro): 0.9290\n",
      "\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       581\n",
      "           1       0.95      0.96      0.95       695\n",
      "           2       0.85      0.80      0.82       159\n",
      "           3       0.94      0.92      0.93       275\n",
      "           4       0.89      0.88      0.89       224\n",
      "           5       0.72      0.71      0.72        66\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.89      0.88      0.88      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=18, out_features=128, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.3, inplace=False)\n",
       "   (3): Linear(in_features=128, out_features=32, bias=True)\n",
       "   (4): ReLU()\n",
       "   (5): Linear(in_features=32, out_features=6, bias=True)\n",
       " ),\n",
       " {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3},\n",
       " np.float64(0.929),\n",
       " 0.92854091877661,\n",
       " 0.880023405286208,\n",
       " 0.929)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNNEmbf1(\n",
    "    bert_logits_file['logits'], roberta_logits_file['logits'], electra_logits_file['logits'],\n",
    "    bert_logits_test_file['logits'], roberta_logits_test_file['logits'], electra_logits_test_file['logits'],\n",
    "    bert_logits_file['labels'], bert_logits_test_file['labels'],\n",
    "    num_classes=6,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    #n_trials=20,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5bd1dcf-e118-40b2-84e6-ab868683bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Concatenados F1: 0.9230\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Concatena os embeddings (como você fazia com os logits)\n",
    "train_embeddings = np.concatenate([\n",
    "    bert_train['embeddings'], \n",
    "    roberta_train['embeddings'], \n",
    "    electra_train['embeddings']\n",
    "], axis=1)\n",
    "\n",
    "test_embeddings = np.concatenate([\n",
    "    bert_test['embeddings'], \n",
    "    roberta_test['embeddings'], \n",
    "    electra_test['embeddings']\n",
    "], axis=1)\n",
    "\n",
    "# Treina um classificador na concatenação\n",
    "concat_clf = LogisticRegression(max_iter=1000)\n",
    "concat_clf.fit(train_embeddings, bert_train['labels'])\n",
    "\n",
    "# Predição\n",
    "concat_preds = concat_clf.predict(test_embeddings)\n",
    "\n",
    "# F1-score\n",
    "concat_f1 = f1_score(bert_test['labels'], concat_preds, average='weighted')\n",
    "print(f\"Embeddings Concatenados F1: {concat_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b45339aa-dfdb-4a2a-a02e-70b5b5333e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== F1-SCORE INDIVIDUAL ===\n",
      "BERT F1: 0.9242\n",
      "RoBERTa F1: 0.9290\n",
      "ELECTRA F1: 0.9314\n",
      "\n",
      "=== VOTAÇÃO MAJORITÁRIA ===\n",
      "Votação F1: 0.9298\n",
      "\n",
      "=== ORÁCULO ===\n",
      "Oráculo F1: 0.9561\n",
      "\n",
      "=== RESUMO ===\n",
      "BERT:      0.9242\n",
      "RoBERTa:   0.9290\n",
      "ELECTRA:   0.9314\n",
      "Votação:   0.9298\n",
      "Oráculo:   0.9561\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Converter logits para predições\n",
    "bert_preds = np.argmax(bert_logits_test_file['logits'], axis=1)\n",
    "roberta_preds = np.argmax(roberta_logits_test_file['logits'], axis=1)\n",
    "electra_preds = np.argmax(electra_logits_test_file['logits'], axis=1)\n",
    "\n",
    "# Labels verdadeiros\n",
    "true_labels = bert_logits_test_file['labels']\n",
    "\n",
    "# 1. F1 individual de cada modelo\n",
    "print(\"=== F1-SCORE INDIVIDUAL ===\")\n",
    "bert_f1 = f1_score(true_labels, bert_preds, average='weighted')\n",
    "roberta_f1 = f1_score(true_labels, roberta_preds, average='weighted')\n",
    "electra_f1 = f1_score(true_labels, electra_preds, average='weighted')\n",
    "\n",
    "print(f\"BERT F1: {bert_f1:.4f}\")\n",
    "print(f\"RoBERTa F1: {roberta_f1:.4f}\")\n",
    "print(f\"ELECTRA F1: {electra_f1:.4f}\")\n",
    "\n",
    "# 2. Votação majoritária\n",
    "print(\"\\n=== VOTAÇÃO MAJORITÁRIA ===\")\n",
    "voting_preds = []\n",
    "for i in range(len(bert_preds)):\n",
    "    votes = [bert_preds[i], roberta_preds[i], electra_preds[i]]\n",
    "    # Pega o mais votado\n",
    "    majority_vote = max(set(votes), key=votes.count)\n",
    "    voting_preds.append(majority_vote)\n",
    "\n",
    "voting_f1 = f1_score(true_labels, voting_preds, average='weighted')\n",
    "print(f\"Votação F1: {voting_f1:.4f}\")\n",
    "\n",
    "# 3. Oráculo (melhor predição possível)\n",
    "print(\"\\n=== ORÁCULO ===\")\n",
    "oracle_preds = []\n",
    "for i in range(len(bert_preds)):\n",
    "    # Para cada amostra, escolhe a predição que está correta (se alguma estiver)\n",
    "    candidates = [bert_preds[i], roberta_preds[i], electra_preds[i]]\n",
    "    if true_labels[i] in candidates:\n",
    "        oracle_preds.append(true_labels[i])  # Escolhe a correta\n",
    "    else:\n",
    "        oracle_preds.append(bert_preds[i])   # Se nenhuma estiver correta, pega BERT\n",
    "\n",
    "oracle_f1 = f1_score(true_labels, oracle_preds, average='weighted')\n",
    "print(f\"Oráculo F1: {oracle_f1:.4f}\")\n",
    "\n",
    "# Resumo\n",
    "print(\"\\n=== RESUMO ===\")\n",
    "print(f\"BERT:      {bert_f1:.4f}\")\n",
    "print(f\"RoBERTa:   {roberta_f1:.4f}\")\n",
    "print(f\"ELECTRA:   {electra_f1:.4f}\")\n",
    "print(f\"Votação:   {voting_f1:.4f}\")\n",
    "print(f\"Oráculo:   {oracle_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d487fa4d-4435-4741-9010-ad89a12695f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c235ac-a5bc-4137-904d-21450e7d9350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "046aa0d9-6e52-4ba0-a0a5-71253f0e21b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.0858\n",
      "Epoch 2 - Loss: 0.0451\n",
      "Epoch 3 - Loss: 0.0435\n",
      "Epoch 4 - Loss: 0.0407\n",
      "Epoch 5 - Loss: 0.0379\n",
      "Val Loss: 0.0499\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.1065\n",
      "Epoch 2 - Loss: 0.0549\n",
      "Epoch 3 - Loss: 0.0481\n",
      "Epoch 4 - Loss: 0.0491\n",
      "Epoch 5 - Loss: 0.0471\n",
      "Val Loss: 0.0390\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.0756\n",
      "Epoch 2 - Loss: 0.0433\n",
      "Epoch 3 - Loss: 0.0461\n",
      "Epoch 4 - Loss: 0.0408\n",
      "Epoch 5 - Loss: 0.0360\n",
      "Val Loss: 0.0504\n",
      "Testando: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.0846\n",
      "Epoch 2 - Loss: 0.0533\n",
      "Epoch 3 - Loss: 0.0480\n",
      "Epoch 4 - Loss: 0.0415\n",
      "Epoch 5 - Loss: 0.0421\n",
      "Val Loss: 0.0393\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.1024\n",
      "Epoch 2 - Loss: 0.0432\n",
      "Epoch 3 - Loss: 0.0401\n",
      "Epoch 4 - Loss: 0.0355\n",
      "Epoch 5 - Loss: 0.0362\n",
      "Val Loss: 0.0401\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.1140\n",
      "Epoch 2 - Loss: 0.0581\n",
      "Epoch 3 - Loss: 0.0497\n",
      "Epoch 4 - Loss: 0.0430\n",
      "Epoch 5 - Loss: 0.0419\n",
      "Val Loss: 0.0465\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1 - Loss: 0.0814\n",
      "Epoch 2 - Loss: 0.0421\n",
      "Epoch 3 - Loss: 0.0400\n",
      "Epoch 4 - Loss: 0.0379\n",
      "Epoch 5 - Loss: 0.0370\n",
      "Val Loss: 0.0417\n",
      "Testando: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1 - Loss: 0.0945\n",
      "Epoch 2 - Loss: 0.0537\n",
      "Epoch 3 - Loss: 0.0446\n",
      "Epoch 4 - Loss: 0.0417\n",
      "Epoch 5 - Loss: 0.0398\n",
      "Val Loss: 0.0427\n",
      "Melhores parâmetros: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Menor loss na validação: 0.03897156381975947\n",
      "AccuracyNN: 0.9260\n",
      "F1-score (weighted): 0.9258\n",
      "F1-score (macro): 0.8802\n",
      "F1-score (micro): 0.9260\n",
      "\n",
      "Relatório de classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       581\n",
      "           1       0.94      0.95      0.95       695\n",
      "           2       0.84      0.79      0.81       159\n",
      "           3       0.94      0.92      0.93       275\n",
      "           4       0.88      0.88      0.88       224\n",
      "           5       0.72      0.77      0.74        66\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.88      0.88      0.88      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=2304, out_features=64, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.5, inplace=False)\n",
       "   (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "   (4): ReLU()\n",
       "   (5): Linear(in_features=32, out_features=6, bias=True)\n",
       " ),\n",
       " {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.5},\n",
       " np.float64(0.926),\n",
       " 0.9258432265199642,\n",
       " 0.8801753736550298,\n",
       " 0.926)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_train = np.load('embeddings_google-bert_bert-base-uncased_emotion_train_bert-base-uncased.npz')\n",
    "roberta_train = np.load('embeddings_roberta-base_emotion_train_roberta-base.npz')\n",
    "electra_train = np.load('embeddings_google_electra-base-discriminator_emotion_train_electra-base-discriminator.npz')\n",
    "\n",
    "bert_test = np.load('embeddings_google-bert_bert-base-uncased_emotion_test_bert-base-uncased.npz')\n",
    "roberta_test = np.load('embeddings_roberta-base_emotion_test_roberta-base.npz')\n",
    "electra_test = np.load('embeddings_google_electra-base-discriminator_emotion_test_electra-base-discriminator.npz')\n",
    "\n",
    "trainNNEmbf1(\n",
    "    bert_train['embeddings'], roberta_train['embeddings'], electra_train['embeddings'],\n",
    "    bert_test['embeddings'], roberta_test['embeddings'], electra_test['embeddings'],\n",
    "    bert_train['labels'], bert_test['labels'],\n",
    "    num_classes=6,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    #n_trials=20,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a38863-e736-4094-a825-e3e530905528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/20 - lr: 0.00043, hidden_dim1: 195, dropout: 0.49\n",
      "  Epoch 1 - Loss: 0.0226\n",
      "  Epoch 2 - Loss: 0.0102\n",
      "  Epoch 3 - Loss: 0.0100\n",
      "  Epoch 4 - Loss: 0.0106\n",
      "  Epoch 5 - Loss: 0.0103\n",
      "  Val Loss: 0.0042\n",
      "Trial 2/20 - lr: 0.00175, hidden_dim1: 60, dropout: 0.38\n",
      "  Epoch 1 - Loss: 0.0184\n",
      "  Epoch 2 - Loss: 0.0114\n",
      "  Epoch 3 - Loss: 0.0112\n",
      "  Epoch 4 - Loss: 0.0109\n",
      "  Epoch 5 - Loss: 0.0100\n",
      "  Val Loss: 0.0047\n",
      "Trial 3/20 - lr: 0.00018, hidden_dim1: 38, dropout: 0.25\n",
      "  Epoch 1 - Loss: 0.1032\n",
      "  Epoch 2 - Loss: 0.0110\n",
      "  Epoch 3 - Loss: 0.0101\n",
      "  Epoch 4 - Loss: 0.0101\n",
      "  Epoch 5 - Loss: 0.0101\n",
      "  Val Loss: 0.0046\n",
      "Trial 4/20 - lr: 0.00013, hidden_dim1: 221, dropout: 0.46\n",
      "  Epoch 1 - Loss: 0.0497\n",
      "  Epoch 2 - Loss: 0.0104\n",
      "  Epoch 3 - Loss: 0.0099\n",
      "  Epoch 4 - Loss: 0.0096\n",
      "  Epoch 5 - Loss: 0.0098\n",
      "  Val Loss: 0.0045\n",
      "Trial 5/20 - lr: 0.00105, hidden_dim1: 102, dropout: 0.41\n",
      "  Epoch 1 - Loss: 0.0170\n",
      "  Epoch 2 - Loss: 0.0105\n",
      "  Epoch 3 - Loss: 0.0102\n",
      "  Epoch 4 - Loss: 0.0102\n",
      "  Epoch 5 - Loss: 0.0100\n",
      "  Val Loss: 0.0048\n",
      "Trial 6/20 - lr: 0.00011, hidden_dim1: 94, dropout: 0.49\n",
      "  Epoch 1 - Loss: 0.0620\n",
      "  Epoch 2 - Loss: 0.0110\n",
      "  Epoch 3 - Loss: 0.0105\n",
      "  Epoch 4 - Loss: 0.0099\n",
      "  Epoch 5 - Loss: 0.0107\n",
      "  Val Loss: 0.0044\n",
      "Trial 7/20 - lr: 0.00260, hidden_dim1: 89, dropout: 0.26\n",
      "  Epoch 1 - Loss: 0.0155\n",
      "  Epoch 2 - Loss: 0.0107\n",
      "  Epoch 3 - Loss: 0.0103\n",
      "  Epoch 4 - Loss: 0.0111\n",
      "  Epoch 5 - Loss: 0.0099\n",
      "  Val Loss: 0.0049\n",
      "Trial 8/20 - lr: 0.00020, hidden_dim1: 67, dropout: 0.26\n",
      "  Epoch 1 - Loss: 0.0450\n",
      "  Epoch 2 - Loss: 0.0104\n",
      "  Epoch 3 - Loss: 0.0105\n",
      "  Epoch 4 - Loss: 0.0103\n",
      "  Epoch 5 - Loss: 0.0099\n",
      "  Val Loss: 0.0043\n",
      "Trial 9/20 - lr: 0.00033, hidden_dim1: 220, dropout: 0.36\n",
      "  Epoch 1 - Loss: 0.0277\n",
      "  Epoch 2 - Loss: 0.0098\n",
      "  Epoch 3 - Loss: 0.0097\n",
      "  Epoch 4 - Loss: 0.0098\n",
      "  Epoch 5 - Loss: 0.0099\n",
      "  Val Loss: 0.0043\n",
      "Trial 10/20 - lr: 0.00054, hidden_dim1: 58, dropout: 0.29\n",
      "  Epoch 1 - Loss: 0.0446\n",
      "  Epoch 2 - Loss: 0.0104\n",
      "  Epoch 3 - Loss: 0.0102\n",
      "  Epoch 4 - Loss: 0.0107\n",
      "  Epoch 5 - Loss: 0.0097\n",
      "  Val Loss: 0.0049\n",
      "Trial 11/20 - lr: 0.00110, hidden_dim1: 205, dropout: 0.24\n",
      "  Epoch 1 - Loss: 0.0178\n",
      "  Epoch 2 - Loss: 0.0097\n",
      "  Epoch 3 - Loss: 0.0097\n",
      "  Epoch 4 - Loss: 0.0101\n",
      "  Epoch 5 - Loss: 0.0096\n",
      "  Val Loss: 0.0047\n",
      "Trial 12/20 - lr: 0.00031, hidden_dim1: 221, dropout: 0.31\n",
      "  Epoch 1 - Loss: 0.0287\n",
      "  Epoch 2 - Loss: 0.0098\n",
      "  Epoch 3 - Loss: 0.0099\n",
      "  Epoch 4 - Loss: 0.0096\n",
      "  Epoch 5 - Loss: 0.0095\n",
      "  Val Loss: 0.0041\n",
      "Trial 13/20 - lr: 0.00060, hidden_dim1: 171, dropout: 0.44\n",
      "  Epoch 1 - Loss: 0.0201\n",
      "  Epoch 2 - Loss: 0.0099\n",
      "  Epoch 3 - Loss: 0.0100\n",
      "  Epoch 4 - Loss: 0.0098\n",
      "  Epoch 5 - Loss: 0.0101\n",
      "  Val Loss: 0.0042\n",
      "Trial 14/20 - lr: 0.00022, hidden_dim1: 54, dropout: 0.35\n",
      "  Epoch 1 - Loss: 0.0563\n",
      "  Epoch 2 - Loss: 0.0109\n",
      "  Epoch 3 - Loss: 0.0112\n",
      "  Epoch 4 - Loss: 0.0104\n",
      "  Epoch 5 - Loss: 0.0104\n",
      "  Val Loss: 0.0041\n",
      "Trial 15/20 - lr: 0.00102, hidden_dim1: 183, dropout: 0.21\n",
      "  Epoch 1 - Loss: 0.0168\n",
      "  Epoch 2 - Loss: 0.0098\n",
      "  Epoch 3 - Loss: 0.0096\n",
      "  Epoch 4 - Loss: 0.0098\n",
      "  Epoch 5 - Loss: 0.0095\n",
      "  Val Loss: 0.0040\n",
      "Trial 16/20 - lr: 0.00108, hidden_dim1: 140, dropout: 0.25\n",
      "  Epoch 1 - Loss: 0.0153\n",
      "  Epoch 2 - Loss: 0.0108\n",
      "  Epoch 3 - Loss: 0.0099\n",
      "  Epoch 4 - Loss: 0.0099\n",
      "  Epoch 5 - Loss: 0.0100\n",
      "  Val Loss: 0.0054\n",
      "Trial 17/20 - lr: 0.00013, hidden_dim1: 40, dropout: 0.48\n",
      "  Epoch 1 - Loss: 0.2032\n",
      "  Epoch 2 - Loss: 0.0155\n",
      "  Epoch 3 - Loss: 0.0126\n",
      "  Epoch 4 - Loss: 0.0117\n",
      "  Epoch 5 - Loss: 0.0115\n",
      "  Val Loss: 0.0048\n",
      "Trial 18/20 - lr: 0.00437, hidden_dim1: 39, dropout: 0.44\n",
      "  Epoch 1 - Loss: 0.0194\n",
      "  Epoch 2 - Loss: 0.0128\n",
      "  Epoch 3 - Loss: 0.0127\n",
      "  Epoch 4 - Loss: 0.0130\n",
      "  Epoch 5 - Loss: 0.0132\n",
      "  Val Loss: 0.0054\n",
      "Trial 19/20 - lr: 0.00033, hidden_dim1: 55, dropout: 0.23\n",
      "  Epoch 1 - Loss: 0.0626\n",
      "  Epoch 2 - Loss: 0.0103\n",
      "  Epoch 3 - Loss: 0.0107\n",
      "  Epoch 4 - Loss: 0.0101\n",
      "  Epoch 5 - Loss: 0.0102\n",
      "  Val Loss: 0.0045\n",
      "Trial 20/20 - lr: 0.00145, hidden_dim1: 87, dropout: 0.33\n",
      "  Epoch 1 - Loss: 0.0187\n",
      "  Epoch 2 - Loss: 0.0098\n",
      "  Epoch 3 - Loss: 0.0103\n",
      "  Epoch 4 - Loss: 0.0102\n",
      "  Epoch 5 - Loss: 0.0100\n",
      "  Val Loss: 0.0065\n",
      "Melhores parâmetros encontrados: {'lr': 0.0010150667045928567, 'hidden_dim1': 183, 'dropout': 0.21393512381599933}\n",
      "Menor loss na validação: 0.0039681793668773025\n",
      "Accuracy final: 0.9463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=6, out_features=183, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.21393512381599933, inplace=False)\n",
       "   (3): Linear(in_features=183, out_features=32, bias=True)\n",
       "   (4): ReLU()\n",
       "   (5): Linear(in_features=32, out_features=2, bias=True)\n",
       " ),\n",
       " {'lr': 0.0010150667045928567,\n",
       "  'hidden_dim1': 183,\n",
       "  'dropout': 0.21393512381599933},\n",
       " 0.0039681793668773025)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainNNEmb_random(\n",
    "    bert_logits_file['logits'], roberta_logits_file['logits'], electra_logits_file['logits'],\n",
    "    bert_logits_test_file['logits'], roberta_logits_test_file['logits'], electra_logits_test_file['logits'],\n",
    "    bert_logits_file['labels'], bert_logits_test_file['labels'],\n",
    "    num_classes=2,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "    n_trials=20,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b97ccf-55ce-4dbb-b274-693ef4ed3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64576cd4-3a5d-4d87-9487-d44d44e615e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NpzFile 'embeddings_google-bert_bert-base-uncased_imdb_train_bert-base-uncased.npz' with keys: embeddings, labels"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afcc62be-eedb-48b9-87c7-fd52c921df55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testando parâmetros: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.3}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x768 and 3x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     12\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mtrainNNEmbPatienceStack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbert_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroberta_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melectra_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbert_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroberta_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melectra_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbert_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert_test\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# n_trials=30,\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m end_time = time.time()\n\u001b[32m     27\u001b[39m wall_time = end_time - start_time\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mtrainNNEmbPatienceStack\u001b[39m\u001b[34m(bertTrainEmbeddings, robertaTrainEmbeddings, electraTrainEmbeddings, bertTestEmbeddings, robertaTestEmbeddings, electraTestEmbeddings, trainLabels, testLabels, num_classes, val_size, batch_size, max_epochs, patience, device)\u001b[39m\n\u001b[32m     74\u001b[39m X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\u001b[32m     75\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m loss = criterion(outputs, y_batch)\n\u001b[32m     78\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (96x768 and 3x64)"
     ]
    }
   ],
   "source": [
    "bert_train = np.load('embeddings_google-bert_bert-base-uncased_imdb_train_bert-base-uncased.npz')\n",
    "roberta_train = np.load('embeddings_roberta-base_imdb_train_roberta-base.npz')\n",
    "electra_train = np.load('embeddings_google_electra-base-discriminator_imdb_train_electra-base-discriminator.npz')\n",
    "\n",
    "bert_test = np.load('embeddings_google-bert_bert-base-uncased_imdb_test_bert-base-uncased.npz')\n",
    "roberta_test = np.load('embeddings_roberta-base_imdb_test_roberta-base.npz')\n",
    "electra_test = np.load('embeddings_google_electra-base-discriminator_imdb_test_electra-base-discriminator.npz')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trainNNEmbPatienceStack(\n",
    "    bert_train['embeddings'], roberta_train['embeddings'], electra_train['embeddings'],\n",
    "    bert_test['embeddings'], roberta_test['embeddings'], electra_test['embeddings'],\n",
    "    bert_train['labels'], bert_test['labels'],\n",
    "    num_classes=2,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "   # n_trials=30,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "wall_time = end_time - start_time\n",
    "print(f\"Wall time: {wall_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1e0ec4-0264-44db-9252-1fa4f5ba89c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BERT: 0.9405\n",
      "Accuracy RoBERTa: 0.9563\n",
      "Accuracy ELECTRA: 0.9575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_train = np.load('logits_google-bert_bert-base-uncased_train_imdb.npz')\n",
    "roberta_train = np.load('logits_roberta-base_train_imdb.npz')\n",
    "electra_train = np.load('logits_google_electra-base-discriminator_train_imdb.npz')\n",
    "\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_imdb.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_imdb.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_imdb.npz')\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "\n",
    "test_labels = bert_test['labels']  # assumindo que todos têm os mesmos labels\n",
    "\n",
    "# Função para calcular acurácia a partir de logits\n",
    "def accuracy_from_logits(logits, labels):\n",
    "    # Se for binário, logits.shape = [num_examples, 1] ou [num_examples, 2]\n",
    "    if logits.shape[1] == 1:\n",
    "        # aplica sigmoid e threshold 0.5\n",
    "        preds = (1 / (1 + np.exp(-logits))) > 0.5\n",
    "        preds = preds.astype(int).squeeze()\n",
    "    else:\n",
    "        # múltiplas classes → argmax\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# Calcula acurácia de cada modelo\n",
    "acc_bert = accuracy_from_logits(bert_logits, test_labels)\n",
    "acc_roberta = accuracy_from_logits(roberta_logits, test_labels)\n",
    "acc_electra = accuracy_from_logits(electra_logits, test_labels)\n",
    "\n",
    "print(f\"Accuracy BERT: {acc_bert:.4f}\")\n",
    "print(f\"Accuracy RoBERTa: {acc_roberta:.4f}\")\n",
    "print(f\"Accuracy ELECTRA: {acc_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab693eb8-0841-4f5d-93e3-72db388c994a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BERT: 0.6595\n",
      "Accuracy RoBERTa: 0.6683\n",
      "Accuracy ELECTRA: 0.6671\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_train = np.load('logits_google-bert_bert-base-uncased_train_yelp.npz')\n",
    "roberta_train = np.load('logits_roberta-base_train_yelp.npz')\n",
    "electra_train = np.load('logits_google_electra-base-discriminator_train_yelp.npz')\n",
    "\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_yelp.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_yelp.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_yelp.npz')\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "\n",
    "test_labels = bert_test['labels']  # assumindo que todos têm os mesmos labels\n",
    "\n",
    "# Função para calcular acurácia a partir de logits\n",
    "def accuracy_from_logits(logits, labels):\n",
    "    # Se for binário, logits.shape = [num_examples, 1] ou [num_examples, 2]\n",
    "    if logits.shape[1] == 1:\n",
    "        # aplica sigmoid e threshold 0.5\n",
    "        preds = (1 / (1 + np.exp(-logits))) > 0.5\n",
    "        preds = preds.astype(int).squeeze()\n",
    "    else:\n",
    "        # múltiplas classes → argmax\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# Calcula acurácia de cada modelo\n",
    "acc_bert = accuracy_from_logits(bert_logits, test_labels)\n",
    "acc_roberta = accuracy_from_logits(roberta_logits, test_labels)\n",
    "acc_electra = accuracy_from_logits(electra_logits, test_labels)\n",
    "\n",
    "print(f\"Accuracy BERT: {acc_bert:.4f}\")\n",
    "print(f\"Accuracy RoBERTa: {acc_roberta:.4f}\")\n",
    "print(f\"Accuracy ELECTRA: {acc_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2113d2ca-8ae6-4bf7-a14b-fb5414656c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BERT: 0.9405\n",
      "Accuracy RoBERTa: 0.9563\n",
      "Accuracy ELECTRA: 0.9575\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit  # sigmoid estável numericamente\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_train = np.load('logits_google-bert_bert-base-uncased_train_imdb.npz')\n",
    "roberta_train = np.load('logits_roberta-base_train_imdb.npz')\n",
    "electra_train = np.load('logits_google_electra-base-discriminator_train_imdb.npz')\n",
    "\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_imdb.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_imdb.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_imdb.npz')\n",
    "\n",
    "# Verifica se labels são idênticos nos arquivos de teste\n",
    "if not (np.array_equal(bert_test['labels'], roberta_test['labels']) and\n",
    "        np.array_equal(bert_test['labels'], electra_test['labels'])):\n",
    "    raise ValueError(\"Os labels não são idênticos entre os modelos!\")\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "\n",
    "labels = bert_test['labels'].astype(int)  # garante que seja int\n",
    "\n",
    "# Função para calcular acurácia a partir de logits\n",
    "def accuracy_from_logits(logits, labels):\n",
    "    \"\"\"\n",
    "    Calcula a acurácia a partir de logits.\n",
    "    Suporta binário (1 ou 2 dimensões) e multiclasse.\n",
    "    \"\"\"\n",
    "    if logits.ndim == 1 or logits.shape[1] == 1:\n",
    "        # Caso binário com um único logit\n",
    "        preds = (expit(logits) > 0.5).astype(int).squeeze()\n",
    "    else:\n",
    "        # Multiclasse ou binário com dois logits\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# Calcula acurácia de cada modelo\n",
    "acc_bert = accuracy_from_logits(bert_logits, labels)\n",
    "acc_roberta = accuracy_from_logits(roberta_logits, labels)\n",
    "acc_electra = accuracy_from_logits(electra_logits, labels)\n",
    "\n",
    "print(f\"Accuracy BERT: {acc_bert:.4f}\")\n",
    "print(f\"Accuracy RoBERTa: {acc_roberta:.4f}\")\n",
    "print(f\"Accuracy ELECTRA: {acc_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0666b3f7-843c-424e-9cab-848f5f8545a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "[[ 4.3973737 -4.004584 ]\n",
      " [ 4.1616864 -3.0968537]\n",
      " [ 4.043721  -3.580645 ]\n",
      " [ 4.3811207 -4.0590196]\n",
      " [-4.047742   3.6661868]]\n"
     ]
    }
   ],
   "source": [
    "print(bert_logits.shape)\n",
    "print(bert_logits[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bca924c1-8f80-4bcd-a2f8-ec084a75ade0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BERT: 0.9482\n",
      "Accuracy RoBERTa: 0.9525\n",
      "Accuracy ELECTRA: 0.9474\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_train = np.load('logits_google-bert_bert-base-uncased_train_agnews.npz')\n",
    "roberta_train = np.load('logits_roberta-base_train_agnews.npz')\n",
    "electra_train = np.load('logits_google_electra-base-discriminator_train_agnews.npz')\n",
    "\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_agnews.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_agnews.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_agnews.npz')\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "\n",
    "test_labels = bert_test['labels']  # assumindo que todos têm os mesmos labels\n",
    "\n",
    "# Função para calcular acurácia a partir de logits\n",
    "def accuracy_from_logits(logits, labels):\n",
    "    # Se for binário, logits.shape = [num_examples, 1] ou [num_examples, 2]\n",
    "    if logits.shape[1] == 1:\n",
    "        # aplica sigmoid e threshold 0.5\n",
    "        preds = (1 / (1 + np.exp(-logits))) > 0.5\n",
    "        preds = preds.astype(int).squeeze()\n",
    "    else:\n",
    "        # múltiplas classes → argmax\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "# Calcula acurácia de cada modelo\n",
    "acc_bert = accuracy_from_logits(bert_logits, test_labels)\n",
    "acc_roberta = accuracy_from_logits(roberta_logits, test_labels)\n",
    "acc_electra = accuracy_from_logits(electra_logits, test_labels)\n",
    "\n",
    "print(f\"Accuracy BERT: {acc_bert:.4f}\")\n",
    "print(f\"Accuracy RoBERTa: {acc_roberta:.4f}\")\n",
    "print(f\"Accuracy ELECTRA: {acc_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f65c9b2-70e9-495e-82fe-d1c43c231b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oráculo Accuracy: 0.9776\n",
      "Voto Majoritário Accuracy: 0.9596\n",
      "Correlação BERT-RoBERTa: 0.9079\n",
      "Correlação BERT-ELECTRA: 0.9119\n",
      "Correlação RoBERTa-ELECTRA: 0.9383\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_imdb.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_imdb.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_imdb.npz')\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "labels = bert_test['labels']\n",
    "\n",
    "# Função para converter logits binários em predições\n",
    "def logits_to_pred(logits):\n",
    "    if logits.shape[1] == 1:  # logit único\n",
    "        preds = (1 / (1 + np.exp(-logits))) > 0.5\n",
    "        return preds.astype(int).squeeze()\n",
    "    else:  # logit para duas classes\n",
    "        return np.argmax(logits, axis=1)\n",
    "\n",
    "# Predições individuais\n",
    "pred_bert = logits_to_pred(bert_logits)\n",
    "pred_roberta = logits_to_pred(roberta_logits)\n",
    "pred_electra = logits_to_pred(electra_logits)\n",
    "\n",
    "# 1️⃣ Oráculo (se qualquer modelo acerta, conta como acerto)\n",
    "oracle_correct = np.logical_or.reduce([\n",
    "    pred_bert == labels,\n",
    "    pred_roberta == labels,\n",
    "    pred_electra == labels\n",
    "])\n",
    "oracle_acc = oracle_correct.mean()\n",
    "\n",
    "# 2️⃣ Voto majoritário\n",
    "preds_stack = np.vstack([pred_bert, pred_roberta, pred_electra])\n",
    "# Para cada coluna, soma e faz threshold 50%\n",
    "majority_pred = (preds_stack.sum(axis=0) >= 2).astype(int)\n",
    "majority_acc = (majority_pred == labels).mean()\n",
    "\n",
    "# 3️⃣ Correlação entre modelos (Pearson)\n",
    "corr_bert_roberta = pearsonr(pred_bert, pred_roberta)[0]\n",
    "corr_bert_electra = pearsonr(pred_bert, pred_electra)[0]\n",
    "corr_roberta_electra = pearsonr(pred_roberta, pred_electra)[0]\n",
    "\n",
    "# Resultados\n",
    "print(f\"Oráculo Accuracy: {oracle_acc:.4f}\")\n",
    "print(f\"Voto Majoritário Accuracy: {majority_acc:.4f}\")\n",
    "print(f\"Correlação BERT-RoBERTa: {corr_bert_roberta:.4f}\")\n",
    "print(f\"Correlação BERT-ELECTRA: {corr_bert_electra:.4f}\")\n",
    "print(f\"Correlação RoBERTa-ELECTRA: {corr_roberta_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66877eb0-9a80-4e4d-bc40-d60062636193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4a0d8e7-5ad2-42c0-92ae-b8f466bea349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oráculo Accuracy: 0.7702\n",
      "Voto Majoritário Accuracy: 0.3197\n",
      "Correlação BERT-RoBERTa: 0.9357\n",
      "Correlação BERT-ELECTRA: 0.9477\n",
      "Correlação RoBERTa-ELECTRA: 0.9435\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Carrega arquivos NPZ\n",
    "bert_test = np.load('logits_google-bert_bert-base-uncased_test_yelp.npz')\n",
    "roberta_test = np.load('logits_roberta-base_test_yelp.npz')\n",
    "electra_test = np.load('logits_google_electra-base-discriminator_test_yelp.npz')\n",
    "\n",
    "# Extrai logits e labels\n",
    "bert_logits = bert_test['logits']\n",
    "roberta_logits = roberta_test['logits']\n",
    "electra_logits = electra_test['logits']\n",
    "labels = bert_test['labels']\n",
    "\n",
    "# Função para converter logits binários em predições\n",
    "def logits_to_pred(logits):\n",
    "    if logits.shape[1] == 1:  # logit único\n",
    "        preds = (1 / (1 + np.exp(-logits))) > 0.5\n",
    "        return preds.astype(int).squeeze()\n",
    "    else:  # logit para duas classes\n",
    "        return np.argmax(logits, axis=1)\n",
    "\n",
    "# Predições individuais\n",
    "pred_bert = logits_to_pred(bert_logits)\n",
    "pred_roberta = logits_to_pred(roberta_logits)\n",
    "pred_electra = logits_to_pred(electra_logits)\n",
    "\n",
    "# 1️⃣ Oráculo (se qualquer modelo acerta, conta como acerto)\n",
    "oracle_correct = np.logical_or.reduce([\n",
    "    pred_bert == labels,\n",
    "    pred_roberta == labels,\n",
    "    pred_electra == labels\n",
    "])\n",
    "oracle_acc = oracle_correct.mean()\n",
    "\n",
    "# 2️⃣ Voto majoritário\n",
    "preds_stack = np.vstack([pred_bert, pred_roberta, pred_electra])\n",
    "# Para cada coluna, soma e faz threshold 50%\n",
    "majority_pred = (preds_stack.sum(axis=0) >= 2).astype(int)\n",
    "majority_acc = (majority_pred == labels).mean()\n",
    "\n",
    "# 3️⃣ Correlação entre modelos (Pearson)\n",
    "corr_bert_roberta = pearsonr(pred_bert, pred_roberta)[0]\n",
    "corr_bert_electra = pearsonr(pred_bert, pred_electra)[0]\n",
    "corr_roberta_electra = pearsonr(pred_roberta, pred_electra)[0]\n",
    "\n",
    "# Resultados\n",
    "print(f\"Oráculo Accuracy: {oracle_acc:.4f}\")\n",
    "print(f\"Voto Majoritário Accuracy: {majority_acc:.4f}\")\n",
    "print(f\"Correlação BERT-RoBERTa: {corr_bert_roberta:.4f}\")\n",
    "print(f\"Correlação BERT-ELECTRA: {corr_bert_electra:.4f}\")\n",
    "print(f\"Correlação RoBERTa-ELECTRA: {corr_roberta_electra:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f4490f8-649d-4f2f-88b7-427c7974df9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oráculo Accuracy: 0.9720\n",
      "Voto Majoritário Accuracy: 0.9532\n",
      "Acerto entre BERT-RoBERTa: 0.9646\n",
      "Acerto entre BERT-ELECTRA: 0.9657\n",
      "Acerto entre RoBERTa-ELECTRA: 0.9657\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e45f1316-24f8-4e78-a289-af92b226031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testando parâmetros: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1: Train Loss=0.5040, Val Loss=0.4813\n",
      "Epoch 2: Train Loss=0.4954, Val Loss=0.4826\n",
      "Epoch 3: Train Loss=0.4929, Val Loss=0.4840\n",
      "Epoch 4: Train Loss=0.4914, Val Loss=0.4853\n",
      "Early stopping na epoch 4\n",
      "\n",
      "Testando parâmetros: {'lr': 0.001, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1: Train Loss=0.5176, Val Loss=0.4895\n",
      "Epoch 2: Train Loss=0.5044, Val Loss=0.4975\n",
      "Epoch 3: Train Loss=0.5015, Val Loss=0.5039\n",
      "Epoch 4: Train Loss=0.4998, Val Loss=0.5015\n",
      "Early stopping na epoch 4\n",
      "\n",
      "Testando parâmetros: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1: Train Loss=0.5005, Val Loss=0.4806\n",
      "Epoch 2: Train Loss=0.4939, Val Loss=0.4752\n",
      "Epoch 3: Train Loss=0.4913, Val Loss=0.4791\n",
      "Epoch 4: Train Loss=0.4905, Val Loss=0.4727\n",
      "Epoch 5: Train Loss=0.4900, Val Loss=0.4760\n",
      "Epoch 6: Train Loss=0.4890, Val Loss=0.4782\n",
      "Epoch 7: Train Loss=0.4884, Val Loss=0.4742\n",
      "Early stopping na epoch 7\n",
      "\n",
      "Testando parâmetros: {'lr': 0.001, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1: Train Loss=0.5113, Val Loss=0.4871\n",
      "Epoch 2: Train Loss=0.5015, Val Loss=0.4820\n",
      "Epoch 3: Train Loss=0.4994, Val Loss=0.4774\n",
      "Epoch 4: Train Loss=0.4984, Val Loss=0.4772\n",
      "Epoch 5: Train Loss=0.4978, Val Loss=0.4756\n",
      "Epoch 6: Train Loss=0.4965, Val Loss=0.4774\n",
      "Epoch 7: Train Loss=0.4971, Val Loss=0.4834\n",
      "Epoch 8: Train Loss=0.4958, Val Loss=0.4765\n",
      "Early stopping na epoch 8\n",
      "\n",
      "Testando parâmetros: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.3}\n",
      "Epoch 1: Train Loss=0.4996, Val Loss=0.4807\n",
      "Epoch 2: Train Loss=0.4896, Val Loss=0.4834\n",
      "Epoch 3: Train Loss=0.4862, Val Loss=0.4795\n",
      "Epoch 4: Train Loss=0.4843, Val Loss=0.4832\n",
      "Epoch 5: Train Loss=0.4824, Val Loss=0.4806\n",
      "Epoch 6: Train Loss=0.4818, Val Loss=0.4829\n",
      "Early stopping na epoch 6\n",
      "\n",
      "Testando parâmetros: {'lr': 0.0005, 'hidden_dim1': 64, 'dropout': 0.5}\n",
      "Epoch 1: Train Loss=0.5123, Val Loss=0.4940\n",
      "Epoch 2: Train Loss=0.4979, Val Loss=0.4987\n",
      "Epoch 3: Train Loss=0.4941, Val Loss=0.5103\n",
      "Epoch 4: Train Loss=0.4918, Val Loss=0.5160\n",
      "Early stopping na epoch 4\n",
      "\n",
      "Testando parâmetros: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Epoch 1: Train Loss=0.4956, Val Loss=0.4874\n",
      "Epoch 2: Train Loss=0.4879, Val Loss=0.4772\n",
      "Epoch 3: Train Loss=0.4859, Val Loss=0.4772\n",
      "Epoch 4: Train Loss=0.4842, Val Loss=0.4748\n",
      "Epoch 5: Train Loss=0.4833, Val Loss=0.4766\n",
      "Epoch 6: Train Loss=0.4822, Val Loss=0.4790\n",
      "Epoch 7: Train Loss=0.4819, Val Loss=0.4739\n",
      "Epoch 8: Train Loss=0.4815, Val Loss=0.4808\n",
      "Epoch 9: Train Loss=0.4810, Val Loss=0.4731\n",
      "Epoch 10: Train Loss=0.4805, Val Loss=0.4715\n",
      "Epoch 11: Train Loss=0.4802, Val Loss=0.4831\n",
      "Epoch 12: Train Loss=0.4800, Val Loss=0.4701\n",
      "Epoch 13: Train Loss=0.4792, Val Loss=0.4740\n",
      "Epoch 14: Train Loss=0.4788, Val Loss=0.4796\n",
      "Epoch 15: Train Loss=0.4789, Val Loss=0.4749\n",
      "Early stopping na epoch 15\n",
      "\n",
      "Testando parâmetros: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.5}\n",
      "Epoch 1: Train Loss=0.5052, Val Loss=0.4745\n",
      "Epoch 2: Train Loss=0.4946, Val Loss=0.4746\n",
      "Epoch 3: Train Loss=0.4920, Val Loss=0.4769\n",
      "Epoch 4: Train Loss=0.4908, Val Loss=0.4794\n",
      "Early stopping na epoch 4\n",
      "\n",
      "Melhores parâmetros encontrados: {'lr': 0.0005, 'hidden_dim1': 128, 'dropout': 0.3}\n",
      "Menor loss na validação: 0.47005656125362105\n",
      "Accuracy no conjunto de teste: 0.6643\n",
      "Wall time: 716.89 segundos\n"
     ]
    }
   ],
   "source": [
    "bert_train = np.load('embeddings_google-bert_bert-base-uncased_yelp_train_bert-base-uncased.npz')\n",
    "roberta_train = np.load('embeddings_roberta-base_yelp_train_roberta-base.npz')\n",
    "electra_train = np.load('embeddings_google_electra-base-discriminator_yelp_train_electra-base-discriminator.npz')\n",
    "\n",
    "bert_test = np.load('embeddings_google-bert_bert-base-uncased_yelp_test_bert-base-uncased.npz')\n",
    "roberta_test = np.load('embeddings_roberta-base_yelp_test_roberta-base.npz')\n",
    "electra_test = np.load('embeddings_google_electra-base-discriminator_yelp_test_electra-base-discriminator.npz')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "trainNNEmbPatience(\n",
    "    bert_train['embeddings'], roberta_train['embeddings'], electra_train['embeddings'],\n",
    "    bert_test['embeddings'], roberta_test['embeddings'], electra_test['embeddings'],\n",
    "    bert_train['labels'], bert_test['labels'],\n",
    "    num_classes=5,\n",
    "    val_size=0.2,\n",
    "    batch_size=32,\n",
    "   # n_trials=30,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "wall_time = end_time - start_time\n",
    "print(f\"Wall time: {wall_time:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97aedf0e-858d-4453-8cf6-328d3d028810",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'Trainer'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2045\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2045\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2046\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2075\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2075\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2073\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers.trainer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Instalar/atualizar dependências:\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# pip install --upgrade transformers datasets torch evaluate scikit-learn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2048\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2046\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2049\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2050\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2052\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m   2053\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Could not import module 'Trainer'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "# Instalar/atualizar dependências:\n",
    "# pip install --upgrade transformers datasets torch evaluate scikit-learn\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "class BERTClassifier:\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=2):\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "        print(f\"Using device: {device}\")\n",
    "\n",
    "    def compute_metrics(self, eval_preds):\n",
    "        logits, labels = eval_preds\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        \n",
    "        accuracy = evaluate.load(\"accuracy\")\n",
    "        return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]}\n",
    "\n",
    "    def preprocess_function(self, examples):\n",
    "        return self.tokenizer(examples['text'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        # Load IMDB dataset\n",
    "        print(\"Loading IMDB dataset...\")\n",
    "        imdb_dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        print(\"Preprocessing data...\")\n",
    "        train_dataset = imdb_dataset['train'].map(self.preprocess_function, batched=True)\n",
    "        test_dataset = imdb_dataset['test'].map(self.preprocess_function, batched=True)\n",
    "        \n",
    "        # Remove text column and set format\n",
    "        train_dataset = train_dataset.remove_columns(['text'])\n",
    "        test_dataset = test_dataset.remove_columns(['text'])\n",
    "        train_dataset.set_format(\"torch\")\n",
    "        test_dataset.set_format(\"torch\")\n",
    "        \n",
    "        print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "        print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "        \n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=\"./bert_imdb\",\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=3,  # Reduced from 5 for faster training\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"accuracy\",\n",
    "            seed=42,\n",
    "        )\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        print(\"Starting training...\")\n",
    "        trainer.train()\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Evaluating model...\")\n",
    "        eval_results = trainer.evaluate()\n",
    "        \n",
    "        print(f\"\\nFinal Results:\")\n",
    "        print(f\"Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "        \n",
    "        return eval_results\n",
    "\n",
    "# Run the training\n",
    "if __name__ == \"__main__\":\n",
    "    classifier = BERTClassifier()\n",
    "    results = classifier.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5eb83908-1ab8-4252-8608-2a96da69ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0\n",
      "Transformers version: 4.52.4\n",
      "Import error: Could not import module 'pipeline'. Are this object's requirements defined correctly?\n",
      "Please run: pip install --upgrade transformers torch\n"
     ]
    }
   ],
   "source": [
    "# Versão ainda mais simples - teste este código primeiro\n",
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"Transformers version:\", transformers.__version__)\n",
    "    \n",
    "    from transformers import pipeline\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"bert-base-uncased\")\n",
    "    result = classifier(\"This movie is great!\")\n",
    "    print(\"Test successful:\", result)\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(\"Import error:\", e)\n",
    "    print(\"Please run: pip install --upgrade transformers torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a97bfc86-b0de-4830-ad24-eb9388ea31a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 242\u001b[39m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m# Exemplo de uso:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m run_fusion_experiments(\u001b[43mbert_embeddings\u001b[49m, roberta_embeddings, electra_embeddings, labels)\n",
      "\u001b[31mNameError\u001b[39m: name 'bert_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class EmbeddingFusionExperiments:\n",
    "    def __init__(self, bert_emb, roberta_emb, electra_emb, labels, num_classes):\n",
    "        self.bert_emb = bert_emb\n",
    "        self.roberta_emb = roberta_emb\n",
    "        self.electra_emb = electra_emb\n",
    "        self.labels = labels\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    def fusion_method_1_concatenate(self):\n",
    "        \"\"\"Método original: concatenação simples\"\"\"\n",
    "        return np.concatenate([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "    \n",
    "    def fusion_method_2_stack_mean(self):\n",
    "        \"\"\"Stack + average pooling\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.mean(stacked, axis=1)\n",
    "    \n",
    "    def fusion_method_3_stack_max(self):\n",
    "        \"\"\"Stack + max pooling\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.max(stacked, axis=1)\n",
    "    \n",
    "    def fusion_method_4_weighted_average(self):\n",
    "        \"\"\"Weighted average baseado na correlação que você mostrou\"\"\"\n",
    "        # Pesos baseados nas suas correlações (RoBERTa-ELECTRA > BERT-ELECTRA > BERT-RoBERTa)\n",
    "        weights = [0.25, 0.35, 0.4]  # BERT, RoBERTa, ELECTRA\n",
    "        \n",
    "        weighted_sum = (weights[0] * self.bert_emb + \n",
    "                       weights[1] * self.roberta_emb + \n",
    "                       weights[2] * self.electra_emb)\n",
    "        return weighted_sum\n",
    "    \n",
    "    def fusion_method_5_hadamard_product(self):\n",
    "        \"\"\"Produto elemento-wise (Hadamard product)\"\"\"\n",
    "        product = self.bert_emb * self.roberta_emb * self.electra_emb\n",
    "        concat = np.concatenate([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.concatenate([concat, product], axis=1)\n",
    "    \n",
    "    def fusion_method_6_attention_like(self):\n",
    "        \"\"\"Simulação de attention: concat + pesos aprendíveis\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        # Retorna stacked para usar com AttentionFusion model\n",
    "        return stacked\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    \"\"\"Modelo que aprende pesos de atenção para fusão\"\"\"\n",
    "    def __init__(self, embedding_dim, num_models=3, hidden_dim=128, dropout=0.3, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_models = num_models\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Attention weights\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_models, embedding_dim)\n",
    "        batch_size, num_models, embedding_dim = x.shape\n",
    "        \n",
    "        # Calculate attention weights for each model\n",
    "        attention_weights = self.attention(x.view(-1, embedding_dim))  # (batch*models, 1)\n",
    "        attention_weights = attention_weights.view(batch_size, num_models, 1)  # (batch, models, 1)\n",
    "        \n",
    "        # Weighted average\n",
    "        fused = torch.sum(x * attention_weights, dim=1)  # (batch, embedding_dim)\n",
    "        \n",
    "        return self.classifier(fused)\n",
    "\n",
    "class StandardModel(nn.Module):\n",
    "    \"\"\"Modelo padrão para outros métodos de fusão\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim1=128, dropout=0.3, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1, hidden_dim1 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1 // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_and_evaluate_fusion_method(fusion_data, labels, method_name, num_classes, use_attention=False):\n",
    "    \"\"\"Treina e avalia um método de fusão específico\"\"\"\n",
    "    print(f\"\\n=== Testando {method_name} ===\")\n",
    "    \n",
    "    # Split dados\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        fusion_data, labels, test_size=0.2, stratify=labels, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Datasets\n",
    "    if use_attention:\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "        \n",
    "        model = AttentionFusionModel(\n",
    "            embedding_dim=X_train.shape[2], \n",
    "            num_models=X_train.shape[1],\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "        \n",
    "        model = StandardModel(input_dim=X_train.shape[1], num_classes=num_classes)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Treino rápido (sem grid search para teste)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(15):  # menos epochs para teste rápido\n",
    "        # Treino\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validação\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 3:\n",
    "                break\n",
    "    \n",
    "    # Teste final\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    test_acc = correct / total\n",
    "    print(f\"{method_name} - Test Accuracy: {test_acc:.4f}\")\n",
    "    return test_acc\n",
    "\n",
    "def run_fusion_experiments(bert_emb, roberta_emb, electra_emb, labels, num_classes=2):\n",
    "    \"\"\"Executa todos os experimentos de fusão\"\"\"\n",
    "    exp = EmbeddingFusionExperiments(bert_emb, roberta_emb, electra_emb, labels, num_classes)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Método 1: Concatenação original\n",
    "    fusion1 = exp.fusion_method_1_concatenate()\n",
    "    results['Concatenate'] = train_and_evaluate_fusion_method(fusion1, labels, \"Concatenate\", num_classes)\n",
    "    \n",
    "    # Método 2: Stack + Mean\n",
    "    fusion2 = exp.fusion_method_2_stack_mean()\n",
    "    results['Stack + Mean'] = train_and_evaluate_fusion_method(fusion2, labels, \"Stack + Mean\", num_classes)\n",
    "    \n",
    "    # Método 3: Stack + Max\n",
    "    fusion3 = exp.fusion_method_3_stack_max()\n",
    "    results['Stack + Max'] = train_and_evaluate_fusion_method(fusion3, labels, \"Stack + Max\", num_classes)\n",
    "    \n",
    "    # Método 4: Weighted Average\n",
    "    fusion4 = exp.fusion_method_4_weighted_average()\n",
    "    results['Weighted Average'] = train_and_evaluate_fusion_method(fusion4, labels, \"Weighted Average\", num_classes)\n",
    "    \n",
    "    # Método 5: Hadamard Product\n",
    "    fusion5 = exp.fusion_method_5_hadamard_product()\n",
    "    results['Hadamard Product'] = train_and_evaluate_fusion_method(fusion5, labels, \"Hadamard Product\", num_classes)\n",
    "    \n",
    "    # Método 6: Attention Fusion\n",
    "    fusion6 = exp.fusion_method_6_attention_like()\n",
    "    results['Attention Fusion'] = train_and_evaluate_fusion_method(fusion6, labels, \"Attention Fusion\", num_classes, use_attention=True)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"RESULTADOS FINAIS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    for method, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{method:20} {acc:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Exemplo de uso:\n",
    "run_fusion_experiments(bert_embeddings, roberta_embeddings, electra_embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4c1183e-c850-4e91-b411-74ee1668961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shapes:\n",
      "BERT: (25000, 768)\n",
      "RoBERTa: (25000, 768)\n",
      "ELECTRA: (25000, 768)\n",
      "\n",
      "Test embeddings shapes:\n",
      "BERT: (25000, 768)\n",
      "RoBERTa: (25000, 768)\n",
      "ELECTRA: (25000, 768)\n",
      "\n",
      "Labels shapes:\n",
      "Train labels: (25000,)\n",
      "Test labels: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Carregamento dos embeddings\n",
    "bert_train_data = np.load('embeddings_google-bert_bert-base-uncased_imdb_train_bert-base-uncased.npz')\n",
    "roberta_train_data = np.load('embeddings_roberta-base_imdb_train_roberta-base.npz')\n",
    "electra_train_data = np.load('embeddings_google_electra-base-discriminator_imdb_train_electra-base-discriminator.npz')\n",
    "\n",
    "bert_test_data = np.load('embeddings_google-bert_bert-base-uncased_imdb_test_bert-base-uncased.npz')\n",
    "roberta_test_data = np.load('embeddings_roberta-base_imdb_test_roberta-base.npz')\n",
    "electra_test_data = np.load('embeddings_google_electra-base-discriminator_imdb_test_electra-base-discriminator.npz')\n",
    "\n",
    "# Extração para variáveis\n",
    "bert_embeddings = bert_train_data['embeddings']\n",
    "roberta_embeddings = roberta_train_data['embeddings']\n",
    "electra_embeddings = electra_train_data['embeddings']\n",
    "\n",
    "bert_test_embeddings = bert_test_data['embeddings']\n",
    "roberta_test_embeddings = roberta_test_data['embeddings']\n",
    "electra_test_embeddings = electra_test_data['embeddings']\n",
    "\n",
    "# Labels (assumindo que estão nos arquivos)\n",
    "train_labels = bert_train_data['labels']  # ou use qualquer um dos arquivos, labels são iguais\n",
    "test_labels = bert_test_data['labels']\n",
    "\n",
    "print(f\"Train embeddings shapes:\")\n",
    "print(f\"BERT: {bert_embeddings.shape}\")\n",
    "print(f\"RoBERTa: {roberta_embeddings.shape}\")\n",
    "print(f\"ELECTRA: {electra_embeddings.shape}\")\n",
    "\n",
    "print(f\"\\nTest embeddings shapes:\")\n",
    "print(f\"BERT: {bert_test_embeddings.shape}\")\n",
    "print(f\"RoBERTa: {roberta_test_embeddings.shape}\")\n",
    "print(f\"ELECTRA: {electra_test_embeddings.shape}\")\n",
    "\n",
    "print(f\"\\nLabels shapes:\")\n",
    "print(f\"Train labels: {train_labels.shape}\")\n",
    "print(f\"Test labels: {test_labels.shape}\")\n",
    "\n",
    "# Agora você pode executar:\n",
    "results = run_fusion_experiments(bert_embeddings, roberta_embeddings, electra_embeddings, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4a3e1f2-a834-4300-9fe1-c201b3c1d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testando Concatenate ===\n",
      "Concatenate - Test Accuracy: 0.9992\n",
      "\n",
      "=== Testando Stack + Mean ===\n",
      "Stack + Mean - Test Accuracy: 0.9990\n",
      "\n",
      "=== Testando Stack + Max ===\n",
      "Stack + Max - Test Accuracy: 0.9988\n",
      "\n",
      "=== Testando Weighted Average ===\n",
      "Weighted Average - Test Accuracy: 0.9992\n",
      "\n",
      "=== Testando Hadamard Product ===\n",
      "Hadamard Product - Test Accuracy: 0.9988\n",
      "\n",
      "=== Testando Attention Fusion ===\n",
      "Attention Fusion - Test Accuracy: 0.9982\n",
      "\n",
      "==================================================\n",
      "RESULTADOS FINAIS:\n",
      "==================================================\n",
      "Concatenate          0.9992\n",
      "Weighted Average     0.9992\n",
      "Stack + Mean         0.9990\n",
      "Stack + Max          0.9988\n",
      "Hadamard Product     0.9988\n",
      "Attention Fusion     0.9982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Concatenate': 0.9992,\n",
       " 'Stack + Mean': 0.999,\n",
       " 'Stack + Max': 0.9988,\n",
       " 'Weighted Average': 0.9992,\n",
       " 'Hadamard Product': 0.9988,\n",
       " 'Attention Fusion': 0.9982}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fusion_experiments(bert_embeddings, roberta_embeddings, electra_embeddings, train_labels,\n",
    "                      bert_test_embeddings, roberta_test_embeddings, electra_test_embeddings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73b649d7-1906-4fb1-ae7f-66f7ffe7ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class EmbeddingFusionExperiments:\n",
    "    def __init__(self, bert_emb, roberta_emb, electra_emb, labels, num_classes):\n",
    "        self.bert_emb = bert_emb\n",
    "        self.roberta_emb = roberta_emb\n",
    "        self.electra_emb = electra_emb\n",
    "        self.labels = labels\n",
    "        self.num_classes = num_classes\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    def fusion_method_1_concatenate(self):\n",
    "        \"\"\"Método original: concatenação simples\"\"\"\n",
    "        return np.concatenate([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "    \n",
    "    def fusion_method_2_stack_mean(self):\n",
    "        \"\"\"Stack + average pooling\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.mean(stacked, axis=1)\n",
    "    \n",
    "    def fusion_method_3_stack_max(self):\n",
    "        \"\"\"Stack + max pooling\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.max(stacked, axis=1)\n",
    "    \n",
    "    def fusion_method_4_weighted_average(self):\n",
    "        \"\"\"Weighted average baseado na correlação que você mostrou\"\"\"\n",
    "        # Pesos baseados nas suas correlações (RoBERTa-ELECTRA > BERT-ELECTRA > BERT-RoBERTa)\n",
    "        weights = [0.25, 0.35, 0.4]  # BERT, RoBERTa, ELECTRA\n",
    "        \n",
    "        weighted_sum = (weights[0] * self.bert_emb + \n",
    "                       weights[1] * self.roberta_emb + \n",
    "                       weights[2] * self.electra_emb)\n",
    "        return weighted_sum\n",
    "    \n",
    "    def fusion_method_5_hadamard_product(self):\n",
    "        \"\"\"Produto elemento-wise (Hadamard product)\"\"\"\n",
    "        product = self.bert_emb * self.roberta_emb * self.electra_emb\n",
    "        concat = np.concatenate([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        return np.concatenate([concat, product], axis=1)\n",
    "    \n",
    "    def fusion_method_6_attention_like(self):\n",
    "        \"\"\"Simulação de attention: concat + pesos aprendíveis\"\"\"\n",
    "        stacked = np.stack([self.bert_emb, self.roberta_emb, self.electra_emb], axis=1)\n",
    "        # Retorna stacked para usar com AttentionFusion model\n",
    "        return stacked\n",
    "\n",
    "class AttentionFusionModel(nn.Module):\n",
    "    \"\"\"Modelo que aprende pesos de atenção para fusão\"\"\"\n",
    "    def __init__(self, embedding_dim, num_models=3, hidden_dim=128, dropout=0.3, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_models = num_models\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Attention weights\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_models, embedding_dim)\n",
    "        batch_size, num_models, embedding_dim = x.shape\n",
    "        \n",
    "        # Calculate attention weights for each model\n",
    "        attention_weights = self.attention(x.view(-1, embedding_dim))  # (batch*models, 1)\n",
    "        attention_weights = attention_weights.view(batch_size, num_models, 1)  # (batch, models, 1)\n",
    "        \n",
    "        # Weighted average\n",
    "        fused = torch.sum(x * attention_weights, dim=1)  # (batch, embedding_dim)\n",
    "        \n",
    "        return self.classifier(fused)\n",
    "\n",
    "class StandardModel(nn.Module):\n",
    "    \"\"\"Modelo padrão para outros métodos de fusão\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim1=128, dropout=0.3, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1, hidden_dim1 // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1 // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "def train_and_evaluate_fusion_method(fusion_train_data, train_labels, fusion_test_data, test_labels, method_name, num_classes, use_attention=False):\n",
    "    \"\"\"Treina e avalia um método de fusão específico\"\"\"\n",
    "    print(f\"\\n=== Testando {method_name} ===\")\n",
    "    \n",
    "    # Usar dados reais de treino/teste\n",
    "    X_train_full, y_train_full = fusion_train_data, train_labels\n",
    "    X_test, y_test = fusion_test_data, test_labels\n",
    "    \n",
    "    # Split apenas treino em treino/validação\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.2, stratify=y_train_full, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Datasets\n",
    "    if use_attention:\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "        \n",
    "        model = AttentionFusionModel(\n",
    "            embedding_dim=X_train.shape[2], \n",
    "            num_models=X_train.shape[1],\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "        val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "        \n",
    "        model = StandardModel(input_dim=X_train.shape[1], num_classes=num_classes)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Treino rápido (sem grid search para teste)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(15):  # menos epochs para teste rápido\n",
    "        # Treino\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validação\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= 3:\n",
    "                break\n",
    "    \n",
    "    # Teste final\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    test_acc = correct / total\n",
    "    print(f\"{method_name} - Test Accuracy: {test_acc:.4f}\")\n",
    "    return test_acc\n",
    "\n",
    "def run_fusion_experiments(bert_train_emb, roberta_train_emb, electra_train_emb, train_labels,\n",
    "                          bert_test_emb, roberta_test_emb, electra_test_emb, test_labels, num_classes=2):\n",
    "    \"\"\"Executa todos os experimentos de fusão\"\"\"\n",
    "    # Criar objetos para treino e teste\n",
    "    exp_train = EmbeddingFusionExperiments(bert_train_emb, roberta_train_emb, electra_train_emb, train_labels, num_classes)\n",
    "    exp_test = EmbeddingFusionExperiments(bert_test_emb, roberta_test_emb, electra_test_emb, test_labels, num_classes)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Método 1: Concatenação original\n",
    "    fusion1_train = exp_train.fusion_method_1_concatenate()\n",
    "    fusion1_test = exp_test.fusion_method_1_concatenate()\n",
    "    results['Concatenate'] = train_and_evaluate_fusion_method(\n",
    "        fusion1_train, train_labels, fusion1_test, test_labels, \"Concatenate\", num_classes)\n",
    "    \n",
    "    # Método 2: Stack + Mean\n",
    "    fusion2_train = exp_train.fusion_method_2_stack_mean()\n",
    "    fusion2_test = exp_test.fusion_method_2_stack_mean()\n",
    "    results['Stack + Mean'] = train_and_evaluate_fusion_method(\n",
    "        fusion2_train, train_labels, fusion2_test, test_labels, \"Stack + Mean\", num_classes)\n",
    "    \n",
    "    # Método 3: Stack + Max\n",
    "    fusion3_train = exp_train.fusion_method_3_stack_max()\n",
    "    fusion3_test = exp_test.fusion_method_3_stack_max()\n",
    "    results['Stack + Max'] = train_and_evaluate_fusion_method(\n",
    "        fusion3_train, train_labels, fusion3_test, test_labels, \"Stack + Max\", num_classes)\n",
    "    \n",
    "    # Método 4: Weighted Average\n",
    "    fusion4_train = exp_train.fusion_method_4_weighted_average()\n",
    "    fusion4_test = exp_test.fusion_method_4_weighted_average()\n",
    "    results['Weighted Average'] = train_and_evaluate_fusion_method(\n",
    "        fusion4_train, train_labels, fusion4_test, test_labels, \"Weighted Average\", num_classes)\n",
    "    \n",
    "    # Método 5: Hadamard Product\n",
    "    fusion5_train = exp_train.fusion_method_5_hadamard_product()\n",
    "    fusion5_test = exp_test.fusion_method_5_hadamard_product()\n",
    "    results['Hadamard Product'] = train_and_evaluate_fusion_method(\n",
    "        fusion5_train, train_labels, fusion5_test, test_labels, \"Hadamard Product\", num_classes)\n",
    "    \n",
    "    # Método 6: Attention Fusion\n",
    "    fusion6_train = exp_train.fusion_method_6_attention_like()\n",
    "    fusion6_test = exp_test.fusion_method_6_attention_like()\n",
    "    results['Attention Fusion'] = train_and_evaluate_fusion_method(\n",
    "        fusion6_train, train_labels, fusion6_test, test_labels, \"Attention Fusion\", num_classes, use_attention=True)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"RESULTADOS FINAIS:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    for method, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"{method:20} {acc:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb604b95-2c3c-4e59-aafa-585d8030349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testando Concatenate ===\n",
      "Concatenate - Test Accuracy: 0.9513\n",
      "\n",
      "=== Testando Stack + Mean ===\n",
      "Stack + Mean - Test Accuracy: 0.9472\n",
      "\n",
      "=== Testando Stack + Max ===\n",
      "Stack + Max - Test Accuracy: 0.9540\n",
      "\n",
      "=== Testando Weighted Average ===\n",
      "Weighted Average - Test Accuracy: 0.9561\n",
      "\n",
      "=== Testando Hadamard Product ===\n",
      "Hadamard Product - Test Accuracy: 0.9562\n",
      "\n",
      "=== Testando Attention Fusion ===\n",
      "Attention Fusion - Test Accuracy: 0.9524\n",
      "\n",
      "==================================================\n",
      "RESULTADOS FINAIS:\n",
      "==================================================\n",
      "Hadamard Product     0.9562\n",
      "Weighted Average     0.9561\n",
      "Stack + Max          0.9540\n",
      "Attention Fusion     0.9524\n",
      "Concatenate          0.9513\n",
      "Stack + Mean         0.9472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Concatenate': 0.95128,\n",
       " 'Stack + Mean': 0.94716,\n",
       " 'Stack + Max': 0.95396,\n",
       " 'Weighted Average': 0.95612,\n",
       " 'Hadamard Product': 0.95616,\n",
       " 'Attention Fusion': 0.95244}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_fusion_experiments(bert_embeddings, roberta_embeddings, electra_embeddings, train_labels,\n",
    "                      bert_test_embeddings, roberta_test_embeddings, electra_test_embeddings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e835888-9b2c-4886-87e3-911e85883dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'ElectraForSequenceClassification'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2045\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2044\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2045\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2046\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2075\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2075\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2073\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2072\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/pytorch_311_env/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1126\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1140\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers.models.electra'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[61]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ElectraForSequenceClassification\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/transformers/utils/import_utils.py:2048\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2046\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2047\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2049\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2050\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2052\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m   2053\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Could not import module 'ElectraForSequenceClassification'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import ElectraTokenizer\n",
    "\n",
    "from transformers import LongformerForSequenceClassification\n",
    "from transformers import LongformerTokenizer\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import csv\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "batch_size = 8\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "\n",
    "\n",
    "class GenericEncoderModel:\n",
    "    def __init__(self, model_name, training_file_name, model_type, problem_type, num_labels):\n",
    "        self.data = []\n",
    "        self.model_name = model_name\n",
    "        self.training_file_name = training_file_name\n",
    "        self.model_type = model_type\n",
    "        self.problem_type = problem_type\n",
    "        self.tokenizer = self._load_tokenizer()\n",
    "        self.trainer = None\n",
    "        self.num_labels = num_labels\n",
    "        self.model = self._load_model()\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "\n",
    "\n",
    "    def _load_tokenizer(self):\n",
    "        if self.model_type == 'electra':\n",
    "            tokenizer = ElectraTokenizer.from_pretrained(self.model_name)\n",
    "        elif self.model_type == 'longformer':\n",
    "            tokenizer = LongformerTokenizer.from_pretrained(self.model_name)\n",
    "        elif self.model_type == 'bert':\n",
    "            tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "        elif self.model_type == 'roberta':\n",
    "            tokenizer = RobertaTokenizer.from_pretrained(self.model_name)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
    "        \n",
    "        return tokenizer\n",
    "    \n",
    "    def _load_model(self):\n",
    "        # check num labels - use num from the dataset\n",
    "        # check pretrained config class https://huggingface.co/transformers/v3.0.2/main_classes/configuration.html#transformers.PretrainedConfig\n",
    "        \n",
    "        # para cada execucao, guardar arquivo com as predicoes do teste\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(self.model_name,\n",
    "                                                           problem_type=self.problem_type,  num_labels=self.num_labels)\n",
    "        return model\n",
    "\n",
    "    def compute_metrics(self, eval_preds, threshold = 0.5):\n",
    "        logits, labels = eval_preds\n",
    "        if self.problem_type == \"single_label_classification\" :\n",
    "            # single label classification\n",
    "            ptype = None\n",
    "            predictions = np.argmax(logits, axis=-1).reshape(-1,1)\n",
    "            labels_ = labels\n",
    "            metrics = [\"accuracy\", \"micro-f1\", \"macro-f1\"]\n",
    "        elif self.problem_type ==  \"multi_label_classification\":\n",
    "            # multi label classification\n",
    "            ptype = \"multilabel\"\n",
    "            sigmoid = torch.nn.Sigmoid()\n",
    "            probs = sigmoid(torch.Tensor(logits))\n",
    "            predictions = np.zeros(probs.shape)\n",
    "            predictions[np.where(probs > threshold)] = 1\n",
    "            predictions = predictions.astype('int32')\n",
    "            labels_ = labels.astype('int32')\n",
    "            # labels_ = labels\n",
    "            metrics = [\"micro-f1\", \"macro-f1\"]\n",
    "        else:\n",
    "            raise ValueError(\"Wrong problem type\")\n",
    "        # Compute the output\n",
    "        outputs = dict()\n",
    "        if \"accuracy\" in metrics:\n",
    "            metric = evaluate.load(\"accuracy\")\n",
    "            accuracy = metric.compute(predictions=predictions, references=labels_)\n",
    "            outputs[\"accuracy\"] = accuracy[\"accuracy\"]\n",
    "        if \"micro-f1\" in metrics:\n",
    "            metric = evaluate.load(\"f1\", ptype)\n",
    "            f1_micro = metric.compute(predictions=predictions, references=labels_, average = 'micro')\n",
    "            outputs[\"micro-f1\"] = f1_micro[\"f1\"]\n",
    "        if \"macro-f1\" in metrics:\n",
    "            metric = evaluate.load(\"f1\",  ptype)\n",
    "            f1_macro = metric.compute(predictions=predictions, references=labels_, average = 'macro')\n",
    "            outputs[\"macro-f1\"] = f1_macro[\"f1\"]\n",
    "        return outputs\n",
    "    \n",
    "    def train(self, train_dataset, test_dataset, dataset_name):\n",
    "        self.model.resize_token_embeddings(len(self._load_tokenizer()))\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            f\"{self.training_file_name}_{dataset_name}_2\",\n",
    "            eval_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=5,\n",
    "            weight_decay=0.01,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=metric_name,\n",
    "            #push_to_hub=True,\n",
    "        )\n",
    "        trainer = Trainer(\n",
    "            self.model,\n",
    "            args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "        trainer.train()\n",
    "        self.trainer = trainer\n",
    "\n",
    "    def store_logits(self, dataset, dataset_name):\n",
    "        self.model.eval()\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "        all_texts = []\n",
    "\n",
    "        dataloader = self.trainer.get_test_dataloader(dataset)\n",
    "        for batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "                logits = outputs.logits.cpu().numpy()\n",
    "                all_logits.append(logits)\n",
    "                all_labels.append(batch[\"labels\"].cpu().numpy())\n",
    "                all_texts.append(batch[\"input_ids\"].cpu().numpy())  # ou a string original, se preferir\n",
    "\n",
    "        logits = np.concatenate(all_logits)\n",
    "        labels = np.concatenate(all_labels)\n",
    "\n",
    "        np.savez(f\"logits_{self.model_name}_{dataset_name}.npz\", logits=logits, labels=labels)\n",
    "\n",
    "\n",
    "    def store_predictions(self, dataset, predictions, output_csv_path):\n",
    "        \"\"\"\n",
    "        Store predictions along with true labels to a CSV file.\n",
    "        \"\"\"\n",
    "        with open(output_csv_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['prediction', 'label', 'text']) \n",
    "            for text, label, prediction in zip(dataset['text'], dataset['label'], predictions):\n",
    "                writer.writerow([prediction, label, text])\n",
    "\n",
    "    def evaluate(self, test_dataset, dataset_name):\n",
    "        metrics = self.trainer.evaluate()\n",
    "        output_csv_path=f\"metrics_{self.model_name}_{dataset_name}_2.csv\"\n",
    "        \n",
    "        predictions = []\n",
    "        for batch in self.trainer.get_test_dataloader(test_dataset):\n",
    "            outputs = self.model(**batch)\n",
    "            logits = outputs.logits\n",
    "            predicted_class = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(predicted_class.cpu().numpy())\n",
    "\n",
    "        # Store predictions in CSV file\n",
    "        self.store_predictions(self.trainer.eval_dataset, predictions, output_csv_path=f\"predictions_{self.model_name}_{dataset_name}_2.csv\")\n",
    "        \n",
    "        # Write metrics to CSV file\n",
    "        with open(output_csv_path, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            file_is_empty = file.tell() == 0\n",
    "            if file_is_empty:\n",
    "                writer.writerow(['dataset', 'accuracy', 'micro-f1', 'macro-f1'])\n",
    "            \n",
    "            writer.writerow([self.training_file_name, metrics.get('eval_accuracy', 'N/A'),\n",
    "                             metrics.get('eval_micro-f1', 'N/A'), metrics.get('eval_macro-f1', 'N/A')])\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def store_embeddings_only(self, dataset, dataset_name):\n",
    "        \"\"\"\n",
    "        Store only embeddings (lighter version if you don't need logits).\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_embeddings = []\n",
    "        all_labels = []\n",
    "\n",
    "        dataloader = self.trainer.get_test_dataloader(dataset)\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch, output_hidden_states=True)\n",
    "                \n",
    "                # Get embeddings from the last hidden state\n",
    "                last_hidden_states = outputs.hidden_states[-1]\n",
    "                \n",
    "                # Extract embeddings based on model type\n",
    "                if self.model_type in ['bert', 'electra', 'roberta', 'longformer']:\n",
    "                    # Use [CLS] token (first token)\n",
    "                    embeddings = last_hidden_states[:, 0, :].cpu().numpy()\n",
    "                else:\n",
    "                    # Mean pooling\n",
    "                    attention_mask = batch['attention_mask'].unsqueeze(-1).expand(last_hidden_states.size()).float()\n",
    "                    sum_embeddings = torch.sum(last_hidden_states * attention_mask, 1)\n",
    "                    sum_mask = torch.clamp(attention_mask.sum(1), min=1e-9)\n",
    "                    embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n",
    "                \n",
    "                all_embeddings.append(embeddings)\n",
    "                all_labels.append(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "        embeddings = np.concatenate(all_embeddings)\n",
    "        labels = np.concatenate(all_labels)\n",
    "\n",
    "        output_file = f\"embeddings_{self.model_name.replace('/', '_')}_{dataset_name}.npz\"\n",
    "        np.savez_compressed(output_file, \n",
    "                        embeddings=embeddings,\n",
    "                        labels=labels)\n",
    "        \n",
    "        print(f\"Saved embeddings to {output_file}\")\n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "    \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# Importing the Amazon dataset recommended by Cristiano\n",
    "amazon_dataset = load_dataset(\"fancyzhx/amazon_polarity\")\n",
    "imdb_dataset = load_dataset(\"stanfordnlp/imdb\")\n",
    "ag_news_dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "yelp_dataset = load_dataset(\"Yelp/yelp_review_full\")\n",
    "snli_dataset = load_dataset(\"stanfordnlp/snli\")\n",
    "\n",
    "datasets = [imdb_dataset, \n",
    "           # amazon_dataset,\n",
    "            # ag_news_dataset, \n",
    "           # yelp_dataset, \n",
    "            #snli_dataset\n",
    "            ]\n",
    "\n",
    "datasetsNames = ['imdb', \n",
    "                 #'amazon', \n",
    "                 #'agnews', \n",
    "                 #'yelp', \n",
    "        #         'snli'\n",
    "                 ]\n",
    "\n",
    "numLabels = [\n",
    "    2,\n",
    "    #2,\n",
    "    # 4,\n",
    "   # 5,\n",
    "#    3\n",
    "]\n",
    "\n",
    "\n",
    "def preprocess_function(examples, tokenizer, contentKey):\n",
    "    return tokenizer(examples[contentKey], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "datasetStructure = {\n",
    "   # 0: {\n",
    "   #     'contentKey': 'text',\n",
    "   #     'labelKey': 'label'\n",
    "   # },\n",
    "   # 0: {\n",
    "  #      'contentKey': 'content',\n",
    "   #    'labelKey': 'label'\n",
    "   # },\n",
    "   # 0: {\n",
    "   #     'contentKey': 'text',\n",
    "   #     'labelKey': 'label'\n",
    "  #  },\n",
    "    0: {\n",
    "        'contentKey': 'text',\n",
    "        'labelKey': 'label'\n",
    "    },\n",
    "  # 1: {\n",
    "  #      'contentKey': 'premise',\n",
    "  #      'labelKey': 'label'\n",
    "  #  }\n",
    "}\n",
    "\n",
    "# google/electra-base-discriminator\n",
    "# roberta-base\n",
    "\n",
    "for countDataset in range (0, len(datasets)):\n",
    "    \n",
    "    models = [\n",
    "        GenericEncoderModel(\n",
    "            model_name='google/electra-base-discriminator', \n",
    "            training_file_name='electra_training', \n",
    "            model_type='electra', \n",
    "            problem_type='single_label_classification',\n",
    "            num_labels=numLabels[countDataset],\n",
    "        ),\n",
    "        GenericEncoderModel(\n",
    "            model_name='roberta-base', \n",
    "            training_file_name='roberta_training', \n",
    "            model_type='roberta', \n",
    "            problem_type='single_label_classification',\n",
    "            num_labels=numLabels[countDataset],\n",
    "        ),\n",
    "        GenericEncoderModel(\n",
    "            model_name='google-bert/bert-base-uncased', \n",
    "            training_file_name='bert_training', \n",
    "            model_type='bert', \n",
    "            problem_type='single_label_classification',\n",
    "            num_labels=numLabels[countDataset],\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for bertModel in models:\n",
    "        dataset = datasets[countDataset]\n",
    "\n",
    "        structure = datasetStructure.get(countDataset, None)\n",
    "\n",
    "        contentList = dataset['train'][structure['contentKey']]\n",
    "        labelList = dataset['train'][structure['labelKey']]\n",
    "\n",
    "        contentTestList = dataset['test'][structure['contentKey']]\n",
    "        labelTestList = dataset['test'][structure['labelKey']]\n",
    "\n",
    "        train_dataset = dataset['train'].map(lambda x: preprocess_function(x, bertModel.tokenizer, structure['contentKey']), batched=True)\n",
    "        test_dataset = dataset['test'].map(lambda x: preprocess_function(x, bertModel.tokenizer, structure['contentKey']), batched=True)\n",
    "        train_dataset = train_dataset.map(remove_columns=[structure['contentKey']])\n",
    "\n",
    "        example = train_dataset[0]\n",
    "        print(example.keys())\n",
    "\n",
    "        print(bertModel.tokenizer.decode(example['input_ids']))\n",
    "\n",
    "        train_dataset.set_format(\"torch\")\n",
    "        test_dataset.set_format(\"torch\")\n",
    "\n",
    "        bertModel.train(train_dataset=train_dataset, test_dataset=test_dataset, dataset_name=datasetsNames[countDataset])\n",
    "\n",
    "        print(bertModel.evaluate(test_dataset, dataset_name=datasetsNames[countDataset]))\n",
    "        bertModel.store_logits(test_dataset, \"imdb_test\")\n",
    "        bertModel.store_logits(train_dataset, \"imdb_train\")\n",
    "        bertModel.store_embeddings_only(test_dataset, f\"imdb_test_{bertModel.model_name.split('/')[-1]}\")\n",
    "        bertModel.store_embeddings_only(train_dataset, f\"imdb_train_{bertModel.model_name.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b505b16-f0bd-45f5-b590-7212bb224e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
